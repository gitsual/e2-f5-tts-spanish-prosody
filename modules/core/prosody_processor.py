#!/usr/bin/env python3
"""
====================================================================================================
SISTEMA DE MEJORA PROS√ìDICA PARA F5-TTS
====================================================================================================

Descripci√≥n:
    M√≥dulo central del sistema de mejoras pros√≥dicas. Implementa una arquitectura
    vocal completa basada en principios ling√º√≠sticos y ac√∫sticos documentados.

Fundamentos Te√≥ricos:
    - Arco Pros√≥dico (Lieberman, 1967; Pierrehumbert, 1980)
      Modelado natural de curvas de entonaci√≥n en el habla

    - Regla del 3-5-8 (BBC Broadcasting, a√±os 50)
      Patrones r√≠tmicos √≥ptimos para narrativa hablada

    - Sincronizaci√≥n Respiratoria-Sint√°ctica
      Alineaci√≥n de pausas con estructura gramatical

Arquitectura del Sistema:

    PARTE 1: GENERACI√ìN CON HINTS (Fase ligera)
    --------------------------------------------
    - ProsodyHintGenerator: Genera hints para guiar a F5-TTS
    - Operaci√≥n r√°pida, m√≠nimo overhead temporal
    - Mejora la prosodia durante la generaci√≥n inicial

    PARTE 2: POST-PROCESAMIENTO (Fase exhaustiva)
    ----------------------------------------------
    - ProsodyAnalyzer: Analiza caracter√≠sticas ac√∫sticas del audio generado
    - ProsodyProblemDetector: Identifica problemas pros√≥dicos
    - SelectiveRegenerator: Regenera selectivamente segmentos problem√°ticos
    - Operaci√≥n m√°s costosa pero con resultados superiores

Componentes Principales:
    - ProsodyHintGenerator: Generaci√≥n de hints contextuales
    - ProsodyAnalyzer: An√°lisis espectral y temporal
    - ProsodyProblemDetector: Detecci√≥n de anomal√≠as pros√≥dicas
    - SelectiveRegenerator: Correcci√≥n selectiva
    - ProsodyOrchestrator: Orquestaci√≥n global (opcional)

Autor: Sistema de generaci√≥n pros√≥dica F5-TTS
Versi√≥n: 2.0
====================================================================================================
"""

import numpy as np
import librosa
import soundfile as sf
from typing import List, Dict, Tuple, Optional, Any
import re
import time
from dataclasses import dataclass
from pathlib import Path
import logging
import sys

# ====================================================================================================
# CONFIGURACI√ìN DE LOGGING
# ====================================================================================================
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


def _import_orquestador_maestro():
    """Intenta importar ArquitecturaVocalMaestra de forma robusta.
    1) Import absoluto si el m√≥dulo est√° en PYTHONPATH
    2) Import relativo si se ejecuta como paquete
    3) Fallback: a√±adir el directorio actual al sys.path y reintentar absoluto
    """
    from pathlib import Path as _Path
    module_dir = _Path(__file__).parent.resolve()
    # 1. Absoluto
    try:
        from prosody_orchestrator_master import ArquitecturaVocalMaestra  # type: ignore
        return ArquitecturaVocalMaestra
    except Exception as e_abs:
        # 2. Relativo (cuando es paquete)
        try:
            from .prosody_orchestrator_master import ArquitecturaVocalMaestra  # type: ignore
            return ArquitecturaVocalMaestra
        except Exception:
            # 3. Fallback sys.path
            try:
                if str(module_dir) not in sys.path:
                    sys.path.insert(0, str(module_dir))
                from prosody_orchestrator_master import ArquitecturaVocalMaestra  # type: ignore
                return ArquitecturaVocalMaestra
            except Exception as e_fb:
                logger.warning(f"‚ö†Ô∏è No se pudo cargar Orquestador Maestro: {e_fb}")
                return None


# ============================================
# PARTE 1: GENERACI√ìN MEJORADA (LIGERA)
# ============================================

class ProsodyHintGenerator:
    """
    Genera hints/modificaciones para la generaci√≥n inicial
    NO a√±ade mucho tiempo, solo modifica puntos cr√≠ticos
    Basado en arquitectura vocal para lectura documentada

    VERSI√ìN 2.0: Integra el Orquestador Maestro para N p√°rrafos con M frases
    """

    def __init__(self, usar_orquestador_maestro: bool = True):
        self.paragraph_count = 0
        self.sentence_count = 0
        self.rules = self._load_harmonic_rules()
        self.fibonacci_positions = [1, 2, 3, 5, 8, 13, 21]  # Para √©nfasis natural

        # NUEVO: Orquestador maestro
        self.usar_orquestador_maestro = usar_orquestador_maestro
        self.ArquitecturaVocalMaestra = None
        self.orquestador = None
        self.control_matrix = None
        self.texto_completo = None
        if usar_orquestador_maestro:
            self.ArquitecturaVocalMaestra = _import_orquestador_maestro()
            if self.ArquitecturaVocalMaestra is not None:
                logger.info("‚úÖ Orquestador Maestro habilitado")
            else:
                logger.warning("‚ö†Ô∏è Orquestador Maestro no disponible, usando sistema legacy")
                self.usar_orquestador_maestro = False

    def _load_harmonic_rules(self):
        """
        Reglas arm√≥nicas basadas en investigaci√≥n pros√≥dica
        - Arco pros√≥dico: inicio medio-alto ‚Üí descenso gradual ‚Üí cierre -30-50Hz
        - Espiral descendente de 3 p√°rrafos
        - Sincronizaci√≥n respiratoria (12-16 resp/min = pausas de 3.75-5s)
        """
        return {
            # Arquitectura de 3 p√°rrafos (Espiral Descendente)
            'paragraph_tones': [1.0, 1.05, 0.92],  # Base, +3 semitonos, -2 semitonos
            'paragraph_speeds': [145, 160, 130],   # PPM para cada p√°rrafo

            # Reglas de frases (Arco Pros√≥dico)
            'sentence_endings': {
                '.': {'pitch': 0.92, 'pause': 700},   # Descenso definitivo
                '?': {'pitch': 1.18, 'pause': 500},   # Subida 15-20%
                '!': {'pitch': 1.10, 'pause': 600},   # √ânfasis moderado
                ',': {'pitch': 1.02, 'pause': 300},   # Micro-ascenso
                ';': {'pitch': 0.98, 'pause': 400},   # Leve descenso
                ':': {'pitch': 1.00, 'pause': 400},   # Mantener
                '...': {'pitch': 0.95, 'pause': 800}, # Suspensivo
            },

            # Control de resonancia por p√°rrafo
            'resonance_modes': {
                1: 'chest_balanced',     # Voz de pecho equilibrada
                2: 'chest_nasal_bright', # A√±adir brillantez nasal (urgencia)
                3: 'deep_chest'          # M√°xima resonancia de pecho (conclusi√≥n)
            },

            # Par√°metros F5-TTS espec√≠ficos para control pros√≥dico
            'f5_params': {
                'nfe_adjustment': {1: 0, 2: 4, 3: -2},  # Ajuste NFE por p√°rrafo
                'sway_adjustment': {1: 0, 2: -0.1, 3: 0.1},  # Ajuste Sway
                'cfg_adjustment': {1: 0, 2: 0.2, 3: -0.1},  # Ajuste CFG
            }
        }

    def prepare_text_for_generation(self,
                                   text: str,
                                   phrase_idx: int,
                                   total_phrases: int,
                                   paragraph_id: Optional[int] = None) -> Dict:
        """
        Prepara el texto con hints para F5-TTS siguiendo arquitectura vocal

        VERSI√ìN 2.0: Usa Orquestador Maestro si est√° disponible,
        fallback al sistema legacy en caso contrario

        Args:
            text: Texto de la frase
            phrase_idx: √çndice de la frase actual
            total_phrases: Total de frases en el documento
            paragraph_id: ID del p√°rrafo (0, 1, 2...)

        Returns:
            Dict con texto modificado y par√°metros de generaci√≥n
        """

        # NUEVO: Intentar usar Orquestador Maestro primero
        if self.usar_orquestador_maestro and self.control_matrix:
            params_maestro = self.obtener_parametros_maestros(phrase_idx)
            if params_maestro:
                logger.debug(f"üé≠ Usando Orquestador Maestro para frase {phrase_idx + 1}")
                return params_maestro

        # FALLBACK: Sistema legacy (original)
        logger.debug(f"üìù Usando sistema legacy para frase {phrase_idx + 1}")

        # Detectar posici√≥n en la estructura
        is_paragraph_start = self._is_paragraph_start(text, phrase_idx)
        is_paragraph_end = self._is_paragraph_end(text, phrase_idx, total_phrases)
        sentence_type = self._detect_sentence_type(text)

        # Determinar p√°rrafo si no se proporciona
        if paragraph_id is None:
            paragraph_id = self._estimate_paragraph_id(phrase_idx, total_phrases)

        # Calcular par√°metros base seg√∫n arquitectura de 3 p√°rrafos
        base_pitch = self.rules['paragraph_tones'][min(paragraph_id, 2)]
        base_speed = self.rules['paragraph_speeds'][min(paragraph_id, 2)]

        # Ajustes F5-TTS espec√≠ficos
        nfe_adjust = self.rules['f5_params']['nfe_adjustment'].get(min(paragraph_id + 1, 3), 0)
        sway_adjust = self.rules['f5_params']['sway_adjustment'].get(min(paragraph_id + 1, 3), 0)
        cfg_adjust = self.rules['f5_params']['cfg_adjustment'].get(min(paragraph_id + 1, 3), 0)

        # Preparar hints base
        generation_hints = {
            'text': text,
            'pitch_factor': base_pitch,
            'speed': base_speed,
            'extra_params': {
                'nfe_adjustment': nfe_adjust,
                'sway_adjustment': sway_adjust,
                'cfg_adjustment': cfg_adjust,
            },
            'apply_modifications': False,  # Por defecto no modificar
            'maestro_source': False  # Indica que viene del sistema legacy
        }

        # SOLO MODIFICAR PUNTOS CR√çTICOS (Arco Pros√≥dico)

        # Inicio de p√°rrafo: captar atenci√≥n (+2% pitch)
        if is_paragraph_start:
            generation_hints['extra_params']['energy'] = 1.1
            generation_hints['pitch_factor'] *= 1.02
            generation_hints['apply_modifications'] = True
            logger.info(f"üìç Inicio de p√°rrafo detectado: pitch {generation_hints['pitch_factor']:.2f}")

        # Final de p√°rrafo declarativo: cadencia descendente (-8%)
        elif is_paragraph_end and sentence_type == 'declarative':
            generation_hints['text'] = self._add_prosody_hint(text, 'falling')
            generation_hints['pitch_factor'] *= 0.92
            generation_hints['extra_params']['energy'] = 0.9
            generation_hints['apply_modifications'] = True
            logger.info(f"üìç Final de p√°rrafo declarativo: cadencia descendente")

        # Preguntas: subida clara (+15-20%)
        elif sentence_type == 'interrogative':
            generation_hints['text'] = self._add_prosody_hint(text, 'rising')
            generation_hints['pitch_factor'] *= 1.15
            generation_hints['apply_modifications'] = True
            logger.info(f"‚ùì Pregunta detectada: subida pros√≥dica")

        # Exclamaciones: √©nfasis moderado
        elif sentence_type == 'exclamative':
            generation_hints['pitch_factor'] *= 1.10
            generation_hints['extra_params']['energy'] = 1.15
            generation_hints['apply_modifications'] = True
            logger.info(f"‚ùó Exclamaci√≥n detectada: √©nfasis aplicado")

        # Aplicar √©nfasis en posiciones Fibonacci si es palabra clave
        if self._is_fibonacci_position(phrase_idx, total_phrases):
            generation_hints['extra_params']['energy'] = \
                generation_hints['extra_params'].get('energy', 1.0) * 1.08
            logger.debug(f"üî¢ Posici√≥n Fibonacci {phrase_idx}: √©nfasis sutil")

        return generation_hints

    def _add_prosody_hint(self, text: str, hint_type: str) -> str:
        """
        A√±ade hints sutiles al texto para guiar F5-TTS
        Estrategias no invasivas que el modelo puede interpretar
        """
        strategies = {
            'falling': [
                text,  # Original
                text.replace('.', '...') if '.' in text else text,  # Puntos suspensivos para cadencia
                text + ' ' if not text.endswith(' ') else text,  # Espacio extra
            ],
            'rising': [
                text,  # Original
                text.replace('?', '?!') if '?' in text else text,  # √ânfasis en pregunta
                text.replace('?', '??') if '?' in text else text,  # Doble interrogaci√≥n
            ]
        }

        # Usar la primera estrategia v√°lida
        options = strategies.get(hint_type, [text])
        return options[0]

    def _detect_sentence_type(self, text: str) -> str:
        """Detecta el tipo de frase bas√°ndose en puntuaci√≥n"""
        text = text.strip()
        if text.endswith('?') or '¬ø' in text:
            return 'interrogative'
        elif text.endswith('!') or '¬°' in text:
            return 'exclamative'
        elif text.endswith('...'):
            return 'suspensive'
        else:
            return 'declarative'

    def _is_paragraph_start(self, text: str, phrase_idx: int) -> bool:
        """Detecta si es inicio de p√°rrafo"""
        # Primera frase siempre es inicio
        if phrase_idx == 0:
            return True
        # Detectar por formato (tabulaci√≥n, espacios)
        if text.strip().startswith(('\t', '    ', '‚Ä¢', '-', '1.', '2.')):
            return True
        # Detectar por may√∫scula despu√©s de punto y aparte
        if re.match(r'^[A-Z√Å√â√ç√ì√ö√ë]', text.strip()):
            return phrase_idx % 10 == 0  # Aproximaci√≥n: cada 10 frases nuevo p√°rrafo
        return False

    def _is_paragraph_end(self, text: str, phrase_idx: int, total_phrases: int) -> bool:
        """Detecta si es final de p√°rrafo"""
        # √öltima frase siempre es final
        if phrase_idx >= total_phrases - 1:
            return True
        # Detectar por puntuaci√≥n fuerte y longitud
        if text.strip().endswith(('.', '!', '?')) and len(text) > 100:
            return True
        # Aproximaci√≥n por posici√≥n
        return (phrase_idx + 1) % 10 == 0

    def _estimate_paragraph_id(self, phrase_idx: int, total_phrases: int) -> int:
        """Estima el p√°rrafo actual bas√°ndose en la posici√≥n"""
        if total_phrases <= 3:
            return phrase_idx

        # Divisi√≥n en tercios para arquitectura de 3 p√°rrafos
        third = total_phrases // 3
        if phrase_idx < third:
            return 0  # Primer p√°rrafo
        elif phrase_idx < 2 * third:
            return 1  # Segundo p√°rrafo
        else:
            return 2  # Tercer p√°rrafo

    def _is_fibonacci_position(self, phrase_idx: int, total_phrases: int) -> bool:
        """Verifica si la posici√≥n corresponde a la secuencia Fibonacci"""
        # Normalizar a escala de 21 (m√°ximo Fibonacci en nuestra lista)
        if total_phrases <= 21:
            return phrase_idx in self.fibonacci_positions
        else:
            # Escalar proporcionalmente
            scaled_idx = int((phrase_idx / total_phrases) * 21)
            return scaled_idx in self.fibonacci_positions

    def inicializar_orquestador_maestro(self, texto_completo: str, f0_base: float = 185.0):
        """
        Inicializa el orquestador maestro con el texto completo
        Debe llamarse ANTES de procesar frases individuales
        """
        if not self.usar_orquestador_maestro:
            return

        try:
            if getattr(self, 'ArquitecturaVocalMaestra', None) is None:
                self.ArquitecturaVocalMaestra = _import_orquestador_maestro()
            if self.ArquitecturaVocalMaestra is None:
                raise ImportError("ArquitecturaVocalMaestra no disponible")

            self.texto_completo = texto_completo
            self.orquestador = self.ArquitecturaVocalMaestra(f0_base=f0_base)

            # Generar matriz de control completa
            self.control_matrix = self.orquestador.orquestar_lectura_completa(texto_completo)

            logger.info(f"üé≠ Orquestador Maestro inicializado: {len(self.control_matrix)} frases planificadas")

        except Exception as e:
            logger.error(f"‚ùå Error inicializando Orquestador Maestro: {e}")
            self.usar_orquestador_maestro = False

    def obtener_parametros_maestros(self, phrase_idx: int) -> Optional[Dict]:
        """
        Obtiene los par√°metros del orquestador maestro para una frase espec√≠fica
        """
        if not self.usar_orquestador_maestro or not self.control_matrix:
            return None

        if 0 <= phrase_idx < len(self.control_matrix):
            params_maestro = self.control_matrix[phrase_idx]

            # Convertir a formato compatible con el sistema actual
            return {
                'apply_modifications': True,
                'text': params_maestro.texto,
                'pitch_factor': params_maestro.tono_base / 185.0,  # Factor relativo
                'speed': params_maestro.velocidad,
                'extra_params': {
                    'nfe_adjustment': max(0, int(params_maestro.tono_base / 185.0 * 4 - 4)),
                    'sway_adjustment': -0.05 if params_maestro.curva == 'cadencia' else 0.0,
                    'cfg_adjustment': 0.1 if params_maestro.intensidad > 1.1 else 0.0,
                    'energy': params_maestro.intensidad,
                    'pause_after': params_maestro.pausa_final,
                    'contour': params_maestro.curva
                },
                'maestro_source': True,
                'parrafo_id': params_maestro.parrafo_id,
                'funcion_narrativa': self._obtener_funcion_narrativa(params_maestro),
                'enfasis_palabras': params_maestro.enfasis_palabras
            }

        return None

    def _obtener_funcion_narrativa(self, params_maestro) -> str:
        """Determina la funci√≥n narrativa basada en los par√°metros del maestro"""
        if params_maestro.curva == 'ataque':
            return 'apertura'
        elif params_maestro.curva == 'cadencia':
            return 'cierre'
        elif params_maestro.intensidad > 1.2:
            return 'pivote'
        else:
            return 'desarrollo'


# ============================================
# PARTE 2: AN√ÅLISIS Y CORRECCI√ìN (EXHAUSTIVO)
# ============================================

class ProsodyAnalyzer:
    """
    An√°lisis exhaustivo del audio por ventanas de 250ms
    Basado en investigaci√≥n de prosodia y cadencias naturales
    """

    def __init__(self, window_size_ms: int = 250, sample_rate: int = 44100):
        self.window_size_ms = window_size_ms
        self.sample_rate = sample_rate
        self.window_samples = int(sample_rate * window_size_ms / 1000)

    def analyze_complete_audio(self,
                              audio_segments: List[np.ndarray],
                              texts: List[str]) -> List[Dict]:
        """
        Analiza todos los segmentos divididos en ventanas
        Eval√∫a cumplimiento del Arco Pros√≥dico
        """
        analysis_map = []

        for i, (audio, text) in enumerate(zip(audio_segments, texts)):
            # Dividir en ventanas de 250ms con 50% overlap
            windows = self._split_into_windows(audio)

            segment_analysis = {
                'segment_id': i,
                'text': text,
                'text_length': len(text),
                'windows': [],
                'is_paragraph_end': self._is_paragraph_end(text),
                'is_question': '?' in text,
                'is_exclamation': '!' in text,
                'sentence_type': self._detect_sentence_type(text)
            }

            # Analizar cada ventana
            for w_idx, window in enumerate(windows):
                position = w_idx / max(len(windows) - 1, 1)  # 0.0 a 1.0

                window_data = {
                    'window_id': w_idx,
                    'position': position,
                    'position_type': self._classify_position(position),
                    'pitch_mean': self._extract_pitch(window),
                    'energy': np.sqrt(np.mean(window**2)),
                    'spectral_centroid': self._extract_spectral_centroid(window)
                }
                segment_analysis['windows'].append(window_data)

            # Calcular m√©tricas del Arco Pros√≥dico
            if segment_analysis['windows']:
                all_pitches = [w['pitch_mean'] for w in segment_analysis['windows'] if w['pitch_mean'] > 0]
                if all_pitches:
                    # Inicio, medio y final seg√∫n Arco Pros√≥dico
                    segment_analysis['pitch_start'] = np.mean(all_pitches[:max(2, len(all_pitches)//5)])
                    segment_analysis['pitch_middle'] = np.mean(all_pitches[len(all_pitches)//3:2*len(all_pitches)//3])
                    segment_analysis['pitch_end'] = np.mean(all_pitches[-max(2, len(all_pitches)//5):])

                    # Calcular pendiente del arco
                    segment_analysis['arc_slope'] = (segment_analysis['pitch_end'] - segment_analysis['pitch_start']) / segment_analysis['pitch_start']

            analysis_map.append(segment_analysis)

        return analysis_map

    def _split_into_windows(self, audio: np.ndarray) -> List[np.ndarray]:
        """Divide audio en ventanas con 50% overlap"""
        windows = []
        hop = self.window_samples // 2  # 50% overlap

        for i in range(0, len(audio) - self.window_samples, hop):
            windows.append(audio[i:i + self.window_samples])

        return windows

    def _extract_pitch(self, window: np.ndarray) -> float:
        """Extrae pitch fundamental usando librosa piptrack"""
        try:
            # Asegurar que el audio sea float
            window_float = window.astype(float)

            # Usar piptrack para extraer pitch
            pitches, magnitudes = librosa.piptrack(
                y=window_float,
                sr=self.sample_rate,
                fmin=50,   # M√≠nimo para voz humana
                fmax=500,  # M√°ximo para voz hablada
                threshold=0.1
            )

            # Obtener el pitch con mayor magnitud en cada frame
            pitch_values = []
            for t in range(pitches.shape[1]):
                index = magnitudes[:, t].argmax()
                pitch = pitches[index, t]
                if pitch > 0:
                    pitch_values.append(pitch)

            return float(np.mean(pitch_values)) if pitch_values else 0.0

        except Exception as e:
            logger.warning(f"Error extrayendo pitch: {e}")
            return 0.0

    def _extract_spectral_centroid(self, window: np.ndarray) -> float:
        """Extrae centroide espectral (brillantez)"""
        try:
            centroid = librosa.feature.spectral_centroid(
                y=window.astype(float),
                sr=self.sample_rate
            )
            return float(np.mean(centroid))
        except:
            return 0.0

    def _classify_position(self, position: float) -> str:
        """Clasifica posici√≥n seg√∫n el Arco Pros√≥dico"""
        if position < 0.15:
            return 'attack'  # Inicio (captar atenci√≥n)
        elif position < 0.7:
            return 'sustain'  # Desarrollo
        elif position < 0.85:
            return 'decay'   # Pre-cadencia
        else:
            return 'release'  # Cadencia final

    def _is_paragraph_end(self, text: str) -> bool:
        """Detecta final de p√°rrafo por puntuaci√≥n"""
        return bool(re.search(r'[.!?]\s*$', text.strip()))

    def _detect_sentence_type(self, text: str) -> str:
        """Clasifica tipo de oraci√≥n"""
        text = text.strip()
        if '?' in text or text.endswith('?'):
            return 'interrogative'
        elif '!' in text or text.endswith('!'):
            return 'exclamative'
        elif text.endswith('...'):
            return 'suspensive'
        else:
            return 'declarative'


class ProsodyProblemDetector:
    """
    Detecta problemas espec√≠ficos en la prosodia seg√∫n reglas documentadas
    Eval√∫a cumplimiento del Arco Pros√≥dico y la Regla del 3-5-8

    VERSI√ìN 2.0: Detecta patrones pros√≥dicos espec√≠ficos m√°s sutiles
    """

    def __init__(self):
        self.rules = {
            # Basado en Arco Pros√≥dico (Pierrehumbert, 1980)
            'paragraph_end_drop': -0.08,      # Ca√≠da del 8% al final
            'question_rise': 0.15,            # Subida 15-20% en preguntas
            'transition_max_jump': 0.25,      # M√°ximo salto entre frases
            'arc_slope_ideal': -0.05,         # Pendiente ideal del arco
            'start_energy_boost': 0.02,       # Boost inicial del 2%

            # NUEVO: Reglas espec√≠ficas del texto ejemplo
            'micro_ascenso_esperado': 0.03,   # +3% en palabras clave
            'enfasis_especial': 0.08,         # +8% en palabras importantes
            'mantener_tension': -0.02,        # M√°ximo -2% de ca√≠da cuando debe mantenerse
            'descenso_final_fuerte': -0.12,   # -12% en finales definitivos
            'velocidad_variacion': 0.15,      # 15% variaci√≥n de velocidad entre p√°rrafos
        }

        # Umbrales de severidad REDUCIDOS para ser m√°s agresivo
        self.severity_thresholds = {
            'critical': 0.3,   # Era 0.5, ahora m√°s agresivo
            'moderate': 0.2,   # Era 0.3, ahora m√°s agresivo
            'minor': 0.1       # Era 0.15, ahora m√°s agresivo
        }

        # NUEVO: Palabras clave que requieren patrones espec√≠ficos (del texto ejemplo)
        self.palabras_especiales = {
            'enfasis_alto': ['diferente', 'incre√≠ble', 'importante', 'fundamental', 'crucial'],
            'micro_ascenso': ['jazm√≠n', 'sal marina', 'marina', 'olvidadas', 'amanecer', 'esperanza', 'doraron'],
            'mantener_grave': ['oscuridad', 'sombras', 'silencio', 'profundidad', 'niebla'],
            'finales_definitivos': ['definitivo', 'final', 'siempre', 'nunca', 'eternidad', 'silencio', 'vigilia']
        }

    def identify_problems(self, analysis_map: List[Dict]) -> List[Dict]:
        """
        Identifica problemas pros√≥dicos y su severidad
        Prioriza seg√∫n impacto en la naturalidad

        VERSI√ìN 2.0: Detecta patrones pros√≥dicos espec√≠ficos m√°s sutiles
        """
        problems = []

        for i, segment in enumerate(analysis_map):
            # Solo verificar ventanas finales para cadencias
            ending_windows = [w for w in segment['windows'] if w['position_type'] == 'release']

            if not ending_windows:
                continue

            last_window = ending_windows[-1]

            # Problema 1: Final de p√°rrafo sin ca√≠da (cr√≠tico para naturalidad)
            if segment['is_paragraph_end'] and segment['sentence_type'] == 'declarative':
                if 'pitch_start' in segment and 'pitch_end' in segment:
                    expected_drop = segment['pitch_start'] * (1 + self.rules['paragraph_end_drop'])
                    actual = segment['pitch_end']

                    if actual > expected_drop and actual > 0:
                        severity = abs(actual - expected_drop) / max(expected_drop, 1)
                        problems.append({
                            'segment_id': i,
                            'window_id': last_window['window_id'],
                            'type': 'missing_paragraph_cadence',
                            'severity': severity,
                            'current_pitch': actual,
                            'expected_pitch': expected_drop,
                            'description': f"Falta cadencia descendente en final de p√°rrafo"
                        })

            # Problema 2: Pregunta sin subida (cr√≠tico para comprensi√≥n)
            elif segment['is_question']:
                if 'pitch_middle' in segment and 'pitch_end' in segment:
                    expected_rise = segment['pitch_middle'] * (1 + self.rules['question_rise'])
                    actual = segment['pitch_end']

                    if actual < expected_rise and actual > 0:
                        severity = abs(expected_rise - actual) / max(expected_rise, 1)
                        problems.append({
                            'segment_id': i,
                            'window_id': last_window['window_id'],
                            'type': 'missing_question_rise',
                            'severity': severity,
                            'current_pitch': actual,
                            'expected_pitch': expected_rise,
                            'description': f"Falta subida tonal en pregunta"
                        })

            # NUEVO: Problema 3: Micro-ascensos faltantes en palabras clave
            texto_segment = segment.get('text', '').lower()
            for palabra in self.palabras_especiales['micro_ascenso']:
                if palabra in texto_segment:
                    # Buscar ventanas que contengan la palabra
                    for window in segment['windows']:
                        if palabra in window.get('text_snippet', '').lower():
                            pitch_actual = window.get('pitch_mean', 0)
                            pitch_esperado = pitch_actual * (1 + self.rules['micro_ascenso_esperado'])

                            if pitch_actual < pitch_esperado * 0.95:  # Tolerancia del 5%
                                severity = abs(pitch_esperado - pitch_actual) / max(pitch_esperado, 1)
                                problems.append({
                                    'segment_id': i,
                                    'window_id': window['window_id'],
                                    'type': 'missing_micro_ascenso',
                                    'severity': severity * 1.2,  # M√°s cr√≠tico
                                    'current_pitch': pitch_actual,
                                    'expected_pitch': pitch_esperado,
                                    'palabra_clave': palabra,
                                    'description': f"Falta micro-ascenso en '{palabra}'"
                                })

            # NUEVO: Problema 4: √ânfasis especial insuficiente
            for palabra in self.palabras_especiales['enfasis_alto']:
                if palabra in texto_segment:
                    for window in segment['windows']:
                        if palabra in window.get('text_snippet', '').lower():
                            pitch_actual = window.get('pitch_mean', 0)
                            pitch_esperado = pitch_actual * (1 + self.rules['enfasis_especial'])

                            if pitch_actual < pitch_esperado * 0.9:  # Tolerancia del 10%
                                severity = abs(pitch_esperado - pitch_actual) / max(pitch_esperado, 1)
                                problems.append({
                                    'segment_id': i,
                                    'window_id': window['window_id'],
                                    'type': 'insufficient_emphasis',
                                    'severity': severity * 1.5,  # Muy cr√≠tico
                                    'current_pitch': pitch_actual,
                                    'expected_pitch': pitch_esperado,
                                    'palabra_clave': palabra,
                                    'description': f"√ânfasis insuficiente en '{palabra}'"
                                })

            # NUEVO: Problema 5: Finales definitivos sin descenso fuerte
            for palabra in self.palabras_especiales['finales_definitivos']:
                if palabra in texto_segment and segment.get('is_paragraph_end', False):
                    if 'pitch_start' in segment and 'pitch_end' in segment:
                        expected_drop = segment['pitch_start'] * (1 + self.rules['descenso_final_fuerte'])
                        actual = segment['pitch_end']

                        if actual > expected_drop * 1.1:  # Tolerancia del 10%
                            severity = abs(actual - expected_drop) / max(expected_drop, 1)
                            problems.append({
                                'segment_id': i,
                                'type': 'missing_definitive_ending',
                                'severity': severity * 1.3,  # Muy cr√≠tico
                                'current_pitch': actual,
                                'expected_pitch': expected_drop,
                                'palabra_clave': palabra,
                                'description': f"Final definitivo sin descenso fuerte en '{palabra}'"
                            })

            # Problema 6: Arco pros√≥dico invertido (antinatural)
            if 'arc_slope' in segment:
                if segment['arc_slope'] > 0.1:  # Subida en lugar de bajada
                    severity = min(abs(segment['arc_slope'] - self.rules['arc_slope_ideal']), 1.0)
                    problems.append({
                        'segment_id': i,
                        'type': 'inverted_prosodic_arc',
                        'severity': severity * 0.8,  # Menos cr√≠tico que cadencias
                        'current_slope': segment['arc_slope'],
                        'expected_slope': self.rules['arc_slope_ideal'],
                        'description': f"Arco pros√≥dico invertido (sube en vez de bajar)"
                    })

            # NUEVO: Problema 4: Palabras clave sin √©nfasis especial
            text_lower = segment['text'].lower()
            for categoria, palabras in self.palabras_especiales.items():
                for palabra in palabras:
                    if palabra in text_lower:
                        # Verificar si la palabra tiene el √©nfasis adecuado
                        problema_enfasis = self._verificar_enfasis_palabra(segment, palabra, categoria)
                        if problema_enfasis:
                            problems.append(problema_enfasis)

            # NUEVO: Problema 5: Falta de variaci√≥n de velocidad entre p√°rrafos
            if i > 0:  # No para el primer segmento
                problema_velocidad = self._verificar_variacion_velocidad(analysis_map, i)
                if problema_velocidad:
                    problems.append(problema_velocidad)

            # NUEVO: Problema 6: Finales definitivos sin descenso fuerte
            if self._es_final_definitivo(segment):
                problema_final = self._verificar_final_definitivo(segment, i)
                if problema_final:
                    problems.append(problema_final)

        # Ordenar por severidad (m√°s severos primero)
        return sorted(problems, key=lambda x: x['severity'], reverse=True)

    def _verificar_enfasis_palabra(self, segment: Dict, palabra: str, categoria: str) -> Optional[Dict]:
        """Verifica si una palabra clave tiene el √©nfasis pros√≥dico adecuado"""
        if 'pitch_mean' not in segment or segment['pitch_mean'] <= 0:
            return None

        expected_boost = {
            'enfasis_alto': self.rules['enfasis_especial'],
            'micro_ascenso': self.rules['micro_ascenso_esperado'],
            'mantener_grave': -self.rules['mantener_tension'],
            'finales_definitivos': self.rules['descenso_final_fuerte']
        }.get(categoria, 0)

        # Calcular si el √©nfasis actual es suficiente
        # (Simplificado - en implementaci√≥n real ser√≠a m√°s complejo)
        pitch_variation = segment.get('pitch_end', segment['pitch_mean']) - segment.get('pitch_start', segment['pitch_mean'])
        expected_variation = segment['pitch_mean'] * expected_boost

        if abs(pitch_variation - expected_variation) > abs(expected_variation * 0.5):
            severity = abs(pitch_variation - expected_variation) / max(abs(expected_variation), 1)
            return {
                'segment_id': segment.get('segment_id', 0),
                'type': f'missing_emphasis_{categoria}',
                'severity': min(severity, 1.0),
                'palabra': palabra,
                'current_variation': pitch_variation,
                'expected_variation': expected_variation,
                'description': f"Palabra '{palabra}' necesita √©nfasis {categoria}"
            }

        return None

    def _verificar_variacion_velocidad(self, analysis_map: List[Dict], current_index: int) -> Optional[Dict]:
        """Verifica si hay suficiente variaci√≥n de velocidad entre p√°rrafos"""
        # Implementaci√≥n simplificada - en real ser√≠a m√°s sofisticada
        return None  # Por ahora deshabilitado

    def _es_final_definitivo(self, segment: Dict) -> bool:
        """Determina si un segmento es un final definitivo que necesita descenso fuerte"""
        text = segment.get('text', '').lower()

        # Indicadores de final definitivo
        finales_definitivos = ['final', 'siempre', 'nunca', 'definitivo', 'eternidad', 'para siempre']
        if any(palabra in text for palabra in finales_definitivos):
            return True

        # Final de documento con punto
        if segment.get('is_paragraph_end', False) and text.endswith('.'):
            return True

        return False

    def _verificar_final_definitivo(self, segment: Dict, segment_id: int) -> Optional[Dict]:
        """Verifica si un final definitivo tiene el descenso fuerte requerido"""
        if 'pitch_start' not in segment or 'pitch_end' not in segment:
            return None

        expected_drop = segment['pitch_start'] * (1 + self.rules['descenso_final_fuerte'])
        actual = segment['pitch_end']

        if actual > expected_drop and actual > 0:
            severity = abs(actual - expected_drop) / max(abs(expected_drop), 1)
            return {
                'segment_id': segment_id,
                'type': 'missing_definitive_ending',
                'severity': min(severity, 1.0),
                'current_pitch': actual,
                'expected_pitch': expected_drop,
                'description': f"Final definitivo necesita descenso m√°s fuerte"
            }

        return None


class SelectiveRegenerator:
    """
    Regenera SOLO segmentos con problemas severos
    VERSI√ìN 2.0: M√°s agresivo y espec√≠fico para patrones pros√≥dicos

    M√°ximo 8 regeneraciones con estrategias m√°s espec√≠ficas
    """

    def __init__(self, f5_generator, max_attempts: int = 25, max_fixes: int = 8):
        self.generator = f5_generator
        self.max_attempts = max_attempts
        self.max_fixes = max_fixes  # Aumentado de 5 a 8 para ser m√°s agresivo
        self.hint_generator = ProsodyHintGenerator()

        # Contexto de referencia para F5-TTS
        self.reference_file = None
        self.reference_text = ""

    def set_reference_context(self, ref_file: str, ref_text: str = ""):
        """Configura el contexto de referencia para regeneraciones"""
        self.reference_file = ref_file
        self.reference_text = ref_text

    def fix_critical_problems(self,
                              problems: List[Dict],
                              audio_segments: List[np.ndarray],
                              texts: List[str],
                              severity_threshold: float = 0.3) -> Tuple[List[np.ndarray], Dict]:
        """
        Corrige solo problemas con severity > threshold
        Limitado a max_fixes para mantener velocidad

        Returns:
            Tuple de (audio_segments corregidos, reporte de fixes)
        """
        fixed_segments = audio_segments.copy()
        fix_report = {
            'attempted': 0,
            'successful': 0,
            'failed': 0,
            'fixes': []
        }

        # Filtrar y limitar problemas a corregir
        critical_problems = [p for p in problems if p['severity'] > severity_threshold][:self.max_fixes]

        if not critical_problems:
            logger.info("‚úÖ No se encontraron problemas cr√≠ticos")
            return fixed_segments, fix_report

        logger.info(f"üîß Corrigiendo {len(critical_problems)} problemas cr√≠ticos...")

        for problem in critical_problems:
            seg_id = problem['segment_id']
            fix_report['attempted'] += 1

            logger.info(f"  üéØ Segmento {seg_id}: {problem['type']} (severidad: {problem['severity']:.2f})")

            # Preparar hints espec√≠ficos para el tipo de problema
            hints = self._prepare_correction_hints(problem, texts[seg_id])

            # Intentar regenerar con estrategias progresivas
            best_candidate = None
            best_score = 0

            # L√çMITE ESTRICTO para evitar bucles infinitos
            max_safe_attempts = min(self.max_attempts, 5)  # M√°ximo 5 intentos por problema
            consecutive_failures = 0

            for attempt in range(max_safe_attempts):
                try:
                    # Ajustar par√°metros F5-TTS seg√∫n el intento
                    generation_params = self._adjust_generation_params(problem, attempt)

                    # Validar par√°metros antes de usar
                    if not self._validate_generation_params(generation_params):
                        logger.warning(f"    ‚ö†Ô∏è Par√°metros inv√°lidos en intento {attempt + 1}, usando valores por defecto")
                        generation_params = {
                            'nfe_step': 32,
                            'sway_sampling_coef': -0.5,
                            'cfg_strength': 2.0,
                            'speed': 1.0
                        }

                    # Generar con hints y par√°metros ajustados
                    new_audio = self._generate_with_params(
                        hints['text'],
                        generation_params
                    )

                    # Si el audio est√° vac√≠o, es un fallo
                    if len(new_audio) == 0:
                        consecutive_failures += 1
                        logger.warning(f"    ‚ö†Ô∏è Audio vac√≠o en intento {attempt + 1}")

                        # Si fallan 3 consecutivos, abandonar
                        if consecutive_failures >= 3:
                            logger.warning(f"    ‚ùå Abandonando despu√©s de {consecutive_failures} fallos consecutivos")
                            break
                        continue

                    # Reset contador de fallos si se genera audio
                    consecutive_failures = 0

                    # Evaluar si mejora el problema
                    score = self._evaluate_fix(new_audio, problem)

                    if score > best_score:
                        best_score = score
                        best_candidate = new_audio

                    # Si es suficientemente bueno, parar
                    if score > 0.8:
                        logger.info(f"    ‚úÖ Corregido en intento {attempt + 1} (score: {score:.2f})")
                        break

                except Exception as e:
                    consecutive_failures += 1
                    logger.warning(f"    ‚ö†Ô∏è Error en intento {attempt + 1}: {e}")

                    # Si es el error espec√≠fico de F5-TTS, TERMINAR INMEDIATAMENTE
                    if "must be strictly increasing" in str(e):
                        logger.error(f"    üö® ERROR CR√çTICO F5-TTS DETECTADO: {e}")
                        logger.error(f"    üíÄ Texto problem√°tico: {hints['text']}")
                        logger.error(f"    üõë TERMINANDO EJECUCI√ìN PARA EVITAR BUCLE INFINITO")

                        # Guardar informaci√≥n del error
                        import datetime
                        timestamp = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")

                        error_info = f"""
TERMINATION LOG - {timestamp}
==============================
Error: {e}
Texto: {hints['text']}
Contexto: prosody_enhancement.py - _try_fix_segment_problem
Intento: {attempt + 1}
==============================
"""

                        try:
                            with open("/home/lorty/m2/ROYERBIN/Spanish-F5/generador_estructura_v3_previo/error_critico.log", "a") as f:
                                f.write(error_info)
                        except:
                            pass

                        # Terminar inmediatamente
                        import sys
                        sys.exit(1)

                    # Si fallan 3 consecutivos, abandonar
                    if consecutive_failures >= 3:
                        logger.warning(f"    ‚ùå Abandonando despu√©s de {consecutive_failures} errores consecutivos")
                        break

                    continue

            # Aplicar mejor candidato si mejora significativamente
            if best_candidate is not None and best_score > 0.5:
                fixed_segments[seg_id] = best_candidate
                fix_report['successful'] += 1
                fix_report['fixes'].append({
                    'segment_id': seg_id,
                    'problem_type': problem['type'],
                    'improvement_score': best_score
                })
                logger.info(f"    ‚úÖ Aplicado fix con score {best_score:.2f}")
            else:
                fix_report['failed'] += 1
                logger.warning(f"    ‚ùå No se pudo mejorar suficientemente")

        return fixed_segments, fix_report

    def _prepare_correction_hints(self, problem: Dict, text: str) -> Dict:
        """Prepara hints espec√≠ficos para cada tipo de problema"""

        hints = {'text': text, 'modifications': []}

        if problem['type'] == 'missing_paragraph_cadence':
            # Forzar cadencia descendente
            hints['text'] = text.replace('.', '...')  # Alargar final
            if not text.endswith('...'):
                hints['text'] = hints['text'].rstrip('.') + '...'
            hints['modifications'].append('extended_ending')

        elif problem['type'] == 'missing_question_rise':
            # Forzar subida en pregunta
            hints['text'] = text.replace('?', '?!')  # A√±adir √©nfasis
            if not '¬ø' in text:
                hints['text'] = '¬ø' + hints['text']  # Asegurar apertura
            hints['modifications'].append('emphasized_question')

        elif problem['type'] == 'missing_micro_ascenso':
            # Micro-ascenso en palabra clave
            palabra = problem.get('palabra_clave', '')
            if palabra:
                # Enfatizar la palabra espec√≠fica con marcas de √©nfasis
                hints['text'] = text.replace(palabra, f'*{palabra}*')
                hints['modifications'].append(f'micro_ascenso_{palabra}')
                # Par√°metros espec√≠ficos para micro-ascenso
                hints['pitch_adjustment'] = '+3%'
                hints['target_word'] = palabra

        elif problem['type'] == 'insufficient_emphasis':
            # √ânfasis especial insuficiente
            palabra = problem.get('palabra_clave', '')
            if palabra:
                # Enfatizar fuertemente la palabra
                hints['text'] = text.replace(palabra, f'**{palabra}**')
                hints['modifications'].append(f'enfasis_especial_{palabra}')
                # Par√°metros espec√≠ficos para √©nfasis especial
                hints['pitch_adjustment'] = '+8%'
                hints['energy_boost'] = '+15%'
                hints['target_word'] = palabra

        elif problem['type'] == 'missing_definitive_ending':
            # Final definitivo sin descenso fuerte
            palabra = problem.get('palabra_clave', '')
            # Forzar descenso definitivo muy marcado
            hints['text'] = text.rstrip('.!') + '...'
            if palabra:
                hints['text'] = hints['text'].replace(palabra, f'{palabra}...')
            hints['modifications'].append('descenso_definitivo')
            hints['pitch_adjustment'] = '-12%'
            hints['final_drop'] = 'strong'

        elif problem['type'] == 'inverted_prosodic_arc':
            # Intentar normalizar el arco
            # Dividir en partes y ajustar puntuaci√≥n
            parts = text.split(',')
            if len(parts) > 1:
                # A√±adir pausas intermedias
                hints['text'] = ', '.join(parts[:-1]) + '... ' + parts[-1]
            hints['modifications'].append('arc_normalization')

        return hints

    def _adjust_generation_params(self, problem: Dict, attempt: int) -> Dict:
        """
        Ajusta par√°metros F5-TTS progresivamente seg√∫n el intento
        VERSI√ìN 2.0: Par√°metros m√°s espec√≠ficos y agresivos
        """

        base_params = {
            'nfe_step': 40,  # Aumentado de 32 para m√°s control
            'sway_sampling_coef': -0.5,
            'cfg_strength': 2.2,  # Aumentado para m√°s adherencia
            'speed': 1.0
        }

        # Ajustes espec√≠ficos por tipo de problema
        if problem['type'] == 'missing_paragraph_cadence':
            # Par√°metros AGRESIVOS para cadencias descendentes
            base_params['nfe_step'] = 48 + (attempt * 3)  # Mucho m√°s control
            base_params['sway_sampling_coef'] = -0.7 - (attempt * 0.08)  # Muy negativo
            base_params['cfg_strength'] = 2.5 + (attempt * 0.15)  # Mayor adherencia
            base_params['speed'] = 0.88 - (attempt * 0.03)  # Ralentizar m√°s

        elif problem['type'] == 'missing_question_rise':
            # Par√°metros AGRESIVOS para subidas tonales
            base_params['nfe_step'] = 44 + (attempt * 2)
            base_params['cfg_strength'] = 2.8 + (attempt * 0.2)  # Muy alta adherencia
            base_params['sway_sampling_coef'] = -0.3 - (attempt * 0.06)
            base_params['speed'] = 1.05 + (attempt * 0.02)  # Acelerar ligeramente

        elif problem['type'] == 'inverted_prosodic_arc':
            # Par√°metros para corregir arcos invertidos
            base_params['nfe_step'] = 36 + (attempt * 5)
            base_params['sway_sampling_coef'] = -0.8 + (attempt * 0.03)
            base_params['cfg_strength'] = 2.3 + (attempt * 0.1)

        # NUEVO: Par√°metros para nuevos tipos de problemas
        elif problem['type'] == 'missing_micro_ascenso':
            # Par√°metros espec√≠ficos para micro-ascensos
            base_params['nfe_step'] = 44 + (attempt * 2)
            base_params['cfg_strength'] = 2.4 + (attempt * 0.1)
            base_params['sway_sampling_coef'] = -0.35 - (attempt * 0.04)
            base_params['speed'] = 1.02 + (attempt * 0.01)  # Ligeramente m√°s r√°pido

        elif problem['type'] == 'insufficient_emphasis':
            # Par√°metros AGRESIVOS para √©nfasis especial
            base_params['nfe_step'] = 46 + (attempt * 3)
            base_params['cfg_strength'] = 2.7 + (attempt * 0.15)  # Mayor adherencia
            base_params['sway_sampling_coef'] = -0.45 - (attempt * 0.06)
            base_params['speed'] = 0.95 - (attempt * 0.02)  # M√°s lento para √©nfasis

        elif problem['type'] == 'missing_definitive_ending':
            # Par√°metros EXTREMOS para finales definitivos
            base_params['nfe_step'] = 52 + (attempt * 4)  # M√°ximo control
            base_params['sway_sampling_coef'] = -0.9 - (attempt * 0.1)  # Extremadamente negativo
            base_params['cfg_strength'] = 3.0 + (attempt * 0.2)  # M√°xima adherencia
            base_params['speed'] = 0.82 - (attempt * 0.04)  # Muy lento para √©nfasis

        # LIMITAR valores extremos para evitar el error "t must be strictly increasing" (M√ÅS CONSERVADOR)
        base_params['nfe_step'] = max(16, min(base_params['nfe_step'], 32))  # Entre 16-32 (era 8-48)
        base_params['sway_sampling_coef'] = max(-0.4, min(base_params['sway_sampling_coef'], 0.4))  # Entre -0.4 y 0.4 (era -0.9 a 0.5)
        base_params['cfg_strength'] = max(1.0, min(base_params['cfg_strength'], 2.2))  # Entre 1.0-2.2 (era 1.0-3.0)
        base_params['speed'] = max(0.85, min(base_params['speed'], 1.15))  # Entre 0.85-1.15 (era 0.8-1.2)

        return base_params

    def _validate_generation_params(self, params: Dict) -> bool:
        """
        Valida que los par√°metros est√©n en rangos seguros para F5-TTS
        """
        try:
            # Validar nfe_step
            nfe_step = params.get('nfe_step', 32)
            if not isinstance(nfe_step, (int, float)) or nfe_step < 4 or nfe_step > 100:
                logger.warning(f"nfe_step inv√°lido: {nfe_step}")
                return False

            # Validar sway_sampling_coef
            sway = params.get('sway_sampling_coef', -0.5)
            if not isinstance(sway, (int, float)) or sway < -2.0 or sway > 2.0:
                logger.warning(f"sway_sampling_coef inv√°lido: {sway}")
                return False

            # Validar cfg_strength
            cfg = params.get('cfg_strength', 2.0)
            if not isinstance(cfg, (int, float)) or cfg < 0.5 or cfg > 10.0:
                logger.warning(f"cfg_strength inv√°lido: {cfg}")
                return False

            # Validar speed
            speed = params.get('speed', 1.0)
            if not isinstance(speed, (int, float)) or speed < 0.1 or speed > 3.0:
                logger.warning(f"speed inv√°lido: {speed}")
                return False

            return True

        except Exception as e:
            logger.warning(f"Error validando par√°metros: {e}")
            return False

    def _split_long_sentence(self, sentence: str) -> list:
        """
        Divide frases largas (>120 chars) para evitar errores de interpolaci√≥n F5-TTS
        """
        import re

        if len(sentence) <= 120:
            return [sentence]

        # Dividir por puntos suspensivos seguidos de min√∫scula
        ellipsis_pattern = r'(\.\.\.)(\s+)([a-z√°√©√≠√≥√∫√º√±])'
        if re.search(ellipsis_pattern, sentence):
            parts = re.split(ellipsis_pattern, sentence)
            result = []
            current = ""
            for i, part in enumerate(parts):
                if part == '...':
                    current += part
                    if current.strip():
                        result.append(current.strip())
                    current = ""
                elif re.match(r'\s+', part):
                    continue  # Saltar espacios
                else:
                    current += part
            if current.strip():
                result.append(current.strip())

            # Recursivamente dividir partes largas
            final_result = []
            for part in result:
                if len(part) > 120:
                    final_result.extend(self._split_long_sentence(part))
                else:
                    final_result.append(part)
            return final_result

        # Divisi√≥n por conectores
        connectors = [
            r',\s+(y|pero|cuando|donde|que|como si|mientras)',
            r',\s+(despu√©s|antes|luego|entonces|as√≠ que|por eso)',
        ]

        for pattern in connectors:
            matches = list(re.finditer(pattern, sentence, re.IGNORECASE))
            if matches:
                # Buscar divisi√≥n cerca del centro
                target = len(sentence) // 2
                best_match = min(matches, key=lambda m: abs(m.start() - target))

                split_pos = best_match.start() + 1
                part1 = sentence[:split_pos].strip()
                part2 = sentence[split_pos:].strip()

                if len(part1) > 30 and len(part2) > 30:
                    result = []
                    for part in [part1, part2]:
                        if len(part) > 120:
                            result.extend(self._split_long_sentence(part))
                        else:
                            result.append(part)
                    return result

        # Divisi√≥n por comas cerca del centro
        comma_positions = [m.start() for m in re.finditer(r',', sentence)]
        if comma_positions:
            target = len(sentence) // 2
            best_comma = min(comma_positions, key=lambda x: abs(x - target))

            part1 = sentence[:best_comma + 1].strip()
            part2 = sentence[best_comma + 1:].strip()

            if len(part1) > 30 and len(part2) > 30:
                return [part1, part2]

        # Divisi√≥n por espacios como √∫ltimo recurso
        words = sentence.split()
        if len(words) > 6:
            mid = len(words) // 2
            part1 = ' '.join(words[:mid])
            part2 = ' '.join(words[mid:])
            return [part1, part2]

        return [sentence]

    def _generate_with_params(self, text: str, params: Dict) -> np.ndarray:
        """
        Genera audio con par√°metros espec√≠ficos usando el generador F5-TTS real
        """

        # NUEVO: Dividir texto largo antes de enviarlo a F5-TTS
        if len(text) > 120:
            logger.info(f"üîß Dividiendo texto largo ({len(text)} chars) para evitar errores")
            sentences = self._split_long_sentence(text)

            if len(sentences) > 1:
                logger.info(f"üìä Texto dividido en {len(sentences)} partes:")
                for i, sentence in enumerate(sentences, 1):
                    logger.info(f"   {i}. [{len(sentence):3d} chars] {sentence[:60]}...")

                # Generar audio para cada parte y concatenar
                audio_parts = []
                for sentence in sentences:
                    part_audio = self._generate_with_params(sentence, params)
                    if len(part_audio) > 0:
                        audio_parts.append(part_audio)

                if audio_parts:
                    return np.concatenate(audio_parts)
                else:
                    return np.array([])

        if self.generator is None:
            logger.error("Error: No hay generador F5-TTS disponible para regeneraci√≥n")
            # Retornar array vac√≠o en lugar de ruido aleatorio
            return np.array([])

        try:
            # Usar el generador F5-TTS real con los par√°metros especificados
            if self.reference_file:
                wav, sr, _ = self.generator.infer(
                    ref_file=self.reference_file,
                    ref_text=self.reference_text,
                    gen_text=text,
                    nfe_step=params.get('nfe_step', 32),
                    sway_sampling_coef=params.get('sway_sampling_coef', -0.5),
                    cfg_strength=params.get('cfg_strength', 2.0),
                    speed=params.get('speed', 1.0),
                    remove_silence=False,
                    seed=-1
                )
            else:
                # Fallback sin referencia espec√≠fica
                wav, sr, _ = self.generator.infer(
                    gen_text=text,
                    nfe_step=params.get('nfe_step', 32),
                    sway_sampling_coef=params.get('sway_sampling_coef', -0.5),
                    cfg_strength=params.get('cfg_strength', 2.0),
                    speed=params.get('speed', 1.0),
                    remove_silence=False,
                    seed=-1
                )

            if wav is not None and len(wav) > 0:
                # Normalizar para evitar clipping
                if np.max(np.abs(wav)) > 0:
                    wav = wav / np.max(np.abs(wav)) * 0.9
                return wav
            else:
                logger.warning("F5-TTS retorn√≥ audio vac√≠o")
                return np.array([])

        except Exception as e:
            logger.error(f"Error en generaci√≥n F5-TTS: {e}")
            return np.array([])

    def _evaluate_fix(self, audio: np.ndarray, problem: Dict) -> float:
        """
        Eval√∫a si el audio corrige el problema
        Score de 0 a 1 (1 = perfectamente corregido)
        """

        analyzer = ProsodyAnalyzer()

        # Analizar el segmento corregido
        if problem['type'] in ['missing_paragraph_cadence', 'missing_question_rise']:
            # Analizar el final del audio
            last_quarter = audio[-len(audio)//4:]
            pitch = analyzer._extract_pitch(last_quarter)

            if pitch <= 0:
                return 0.0

            # Calcular proximidad al objetivo
            target = problem['expected_pitch']
            current = problem['current_pitch']

            # Score basado en mejora relativa
            improvement = abs(pitch - target) / abs(current - target)
            score = max(0, 1 - improvement)

        elif problem['type'] == 'inverted_prosodic_arc':
            # Analizar el arco completo
            windows = analyzer._split_into_windows(audio)
            pitches = [analyzer._extract_pitch(w) for w in windows]
            valid_pitches = [p for p in pitches if p > 0]

            if len(valid_pitches) < 3:
                return 0.0

            # Calcular nueva pendiente
            new_slope = (valid_pitches[-1] - valid_pitches[0]) / valid_pitches[0]
            target_slope = problem['expected_slope']

            # Score basado en cercan√≠a a pendiente ideal
            score = max(0, 1 - abs(new_slope - target_slope) / 0.2)

        else:
            score = 0.5  # Score neutral para problemas no definidos

        return min(max(score, 0.0), 1.0)


# ============================================
# ORQUESTADOR PRINCIPAL
# ============================================

class ProsodyOrchestrator:
    """
    Orquesta todo el proceso de mejora pros√≥dica:
    1. Generaci√≥n mejorada con hints (r√°pida)
    2. Post-procesamiento selectivo (opcional)

    Dise√±ado para integrarse con tu generador F5-TTS actual
    """

    def __init__(self, f5_generator=None):
        """
        Args:
            f5_generator: Tu instancia de F5TTS o generador compatible
        """
        self.generator = f5_generator
        self.hint_generator = ProsodyHintGenerator()
        self.analyzer = ProsodyAnalyzer()
        self.detector = ProsodyProblemDetector()
        self.regenerator = SelectiveRegenerator(f5_generator) if f5_generator else None

        # Estad√≠sticas de procesamiento
        self.stats = {
            'total_processed': 0,
            'hints_applied': 0,
            'problems_detected': 0,
            'problems_fixed': 0,
            'processing_time': 0
        }

    def generate_with_prosody(self,
                             texts: List[str],
                             apply_postprocess: bool = True,
                             reference_audio: Optional[str] = None) -> Tuple[List[np.ndarray], Dict]:
        """
        Genera audio con mejoras pros√≥dicas

        Args:
            texts: Lista de frases a generar
            apply_postprocess: Si aplicar post-procesamiento (Fase 2)
            reference_audio: Audio de referencia para clonaci√≥n

        Returns:
            Tuple de (lista de audios generados, reporte de procesamiento)
        """

        start_time = time.time()

        print("üéµ FASE 1: Generaci√≥n con hints pros√≥dicos...")
        audio_segments = []

        # Detectar estructura de p√°rrafos
        paragraph_boundaries = self._detect_paragraph_boundaries(texts)
        total_phrases = len(texts)

        for i, text in enumerate(texts):
            self.stats['total_processed'] += 1

            # Determinar p√°rrafo actual
            paragraph_id = self._get_paragraph_id(i, paragraph_boundaries)

            # Generar hints SOLO para frases cr√≠ticas
            if self._is_critical_position(i, texts):
                hints = self.hint_generator.prepare_text_for_generation(
                    text, i, total_phrases, paragraph_id
                )

                if hints['apply_modifications']:
                    self.stats['hints_applied'] += 1
                    logger.info(f"  üìù Frase {i+1}/{total_phrases}: Aplicando hints pros√≥dicos")

                    # Generar con modificaciones
                    audio = self._generate_with_hints(hints, reference_audio)
                else:
                    # Generar normal
                    audio = self._generate_normal(text, reference_audio)
            else:
                # Generaci√≥n normal para la mayor√≠a de frases
                audio = self._generate_normal(text, reference_audio)

            audio_segments.append(audio)

            # Mostrar progreso
            if (i + 1) % 10 == 0:
                print(f"  Progreso: {i+1}/{total_phrases} frases")

        # Preparar reporte
        report = {
            'phase1_complete': True,
            'segments_generated': len(audio_segments),
            'hints_applied': self.stats['hints_applied'],
            'critical_positions': sum(1 for i in range(len(texts)) if self._is_critical_position(i, texts))
        }

        # FASE 2: Post-procesamiento (opcional)
        if apply_postprocess and self.regenerator:
            print("\nüîç FASE 2: An√°lisis y correcci√≥n selectiva...")

            # Analizar prosodia
            analysis = self.analyzer.analyze_complete_audio(audio_segments, texts)
            problems = self.detector.identify_problems(analysis)

            self.stats['problems_detected'] = len(problems)
            report['problems_found'] = len(problems)
            report['critical_problems'] = len([p for p in problems if p['severity'] > 0.3])

            if problems and report['critical_problems'] > 0:
                print(f"  ‚ö†Ô∏è Encontrados {report['critical_problems']} problemas cr√≠ticos")

                # Corregir solo los cr√≠ticos
                audio_segments, fix_report = self.regenerator.fix_critical_problems(
                    problems, audio_segments, texts
                )

                self.stats['problems_fixed'] = fix_report['successful']
                report['phase2_complete'] = True
                report['segments_fixed'] = fix_report['successful']
                report['fix_details'] = fix_report
            else:
                print("  ‚úÖ No se encontraron problemas cr√≠ticos de prosodia")
                report['phase2_complete'] = True
                report['segments_fixed'] = 0

        # Tiempo total
        self.stats['processing_time'] = time.time() - start_time
        report['total_time'] = self.stats['processing_time']
        report['stats'] = self.stats.copy()

        print(f"\n‚úÖ Procesamiento completado en {report['total_time']:.1f} segundos")

        return audio_segments, report

    def _is_critical_position(self, index: int, texts: List[str]) -> bool:
        """
        Identifica si es una posici√≥n cr√≠tica que necesita hints
        Solo ~20% de las frases son cr√≠ticas para mantener velocidad
        """
        text = texts[index]
        total = len(texts)

        # Criterios para posici√≥n cr√≠tica:

        # 1. Primeras 2 frases (inicio, establecer tono)
        if index < 2:
            return True

        # 2. √öltimas 2 frases (cierre, cadencia final)
        if index >= total - 2:
            return True

        # 3. Preguntas (necesitan subida tonal)
        if '?' in text:
            return True

        # 4. Exclamaciones (necesitan √©nfasis)
        if '!' in text:
            return True

        # 5. Posibles inicios de p√°rrafo (cada ~10 frases)
        if index > 0 and index % 10 == 0:
            return True

        # 6. Posibles finales de p√°rrafo (frases largas con punto)
        if len(text) > 150 and text.strip().endswith('.'):
            return True

        return False

    def _detect_paragraph_boundaries(self, texts: List[str]) -> List[int]:
        """Detecta d√≥nde empiezan los p√°rrafos en el texto"""
        boundaries = [0]

        for i, text in enumerate(texts[1:], 1):
            # Heur√≠sticas para detectar nuevo p√°rrafo

            # 1. Empieza con may√∫scula despu√©s de punto final largo
            if i > 0 and texts[i-1].strip().endswith('.') and len(texts[i-1]) > 100:
                if re.match(r'^[A-Z√Å√â√ç√ì√ö√ë]', text.strip()):
                    boundaries.append(i)

            # 2. Formato especial (listas, t√≠tulos)
            elif text.strip().startswith(('‚Ä¢', '-', '1.', '2.', '3.')):
                boundaries.append(i)

            # 3. Salto grande en longitud (posible cambio de secci√≥n)
            elif i > 0:
                prev_len = len(texts[i-1])
                curr_len = len(text)
                if prev_len > 150 and curr_len < 50:  # P√°rrafo largo seguido de corto
                    boundaries.append(i)

        return sorted(list(set(boundaries)))

    def _get_paragraph_id(self, sentence_idx: int, boundaries: List[int]) -> int:
        """Determina a qu√© p√°rrafo pertenece una frase"""
        for i in range(len(boundaries) - 1):
            if boundaries[i] <= sentence_idx < boundaries[i + 1]:
                return i
        return len(boundaries) - 1

    def _generate_with_hints(self, hints: Dict, reference_audio: Optional[str]) -> np.ndarray:
        """
        Genera audio con hints pros√≥dicos aplicados
        ADAPTAR a tu generador F5-TTS espec√≠fico
        """

        if self.generator:
            # Adaptar a tu implementaci√≥n
            # Por ejemplo:
            # return self.generator.generate(
            #     text=hints['text'],
            #     speed=hints.get('speed', 1.0),
            #     pitch_factor=hints.get('pitch_factor', 1.0),
            #     **hints.get('extra_params', {})
            # )
            pass

        # Placeholder: genera audio dummy
        return self._generate_dummy_audio(hints['text'])

    def _generate_normal(self, text: str, reference_audio: Optional[str]) -> np.ndarray:
        """
        Generaci√≥n normal sin modificaciones
        ADAPTAR a tu generador F5-TTS
        """

        if self.generator:
            # Adaptar a tu implementaci√≥n
            # return self.generator.generate(text)
            pass

        # Placeholder: genera audio dummy
        return self._generate_dummy_audio(text)

    def _generate_dummy_audio(self, text: str) -> np.ndarray:
        """Genera audio dummy para testing (ELIMINAR en producci√≥n)"""
        duration = len(text) * 0.06  # ~60ms por car√°cter
        samples = int(duration * 44100)

        # Simular audio con algo de estructura
        t = np.linspace(0, duration, samples)
        frequency = 200 + np.random.randn() * 50  # Frecuencia base variable
        audio = np.sin(2 * np.pi * frequency * t) * 0.3
        audio *= np.exp(-t / duration)  # Envelope descendente

        return audio


# ============================================
# UTILIDADES Y HELPERS
# ============================================

def smart_concatenate(segments: List[np.ndarray], crossfade_ms: int = 50, sr: int = 44100) -> np.ndarray:
    """
    Concatena segmentos de audio con crossfade suave
    Preserva las pausas naturales entre frases
    """
    if not segments:
        return np.array([])

    if len(segments) == 1:
        return segments[0]

    result = segments[0]
    crossfade_samples = int(crossfade_ms * sr / 1000)

    for next_seg in segments[1:]:
        if len(result) > crossfade_samples and len(next_seg) > crossfade_samples:
            # Aplicar crossfade tipo coseno (m√°s natural)
            t = np.linspace(0, np.pi/2, crossfade_samples)
            fade_out = np.cos(t)
            fade_in = np.sin(t)

            # Aplicar fades
            result[-crossfade_samples:] *= fade_out
            overlap = result[-crossfade_samples:] + next_seg[:crossfade_samples] * fade_in

            # Concatenar
            result = np.concatenate([
                result[:-crossfade_samples],
                overlap,
                next_seg[crossfade_samples:]
            ])
        else:
            # Sin crossfade si los segmentos son muy cortos
            result = np.concatenate([result, next_seg])

    return result


def export_prosody_report(report: Dict, output_path: str):
    """Exporta reporte de procesamiento pros√≥dico"""

    import json
    from datetime import datetime

    report['timestamp'] = datetime.now().isoformat()
    report['version'] = '1.0.0'

    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(report, f, indent=2, ensure_ascii=False)

    print(f"üìä Reporte exportado a: {output_path}")


# ============================================
# FUNCI√ìN PRINCIPAL DE INTEGRACI√ìN
# ============================================

def enhance_f5_tts_generation(
    texts: List[str],
    f5_generator,
    reference_audio: Optional[str] = None,
    apply_postprocess: bool = True,
    save_report: bool = True
) -> Tuple[List[np.ndarray], np.ndarray]:
    """
    Funci√≥n principal para mejorar generaci√≥n F5-TTS con prosodia

    Args:
        texts: Lista de frases a generar
        f5_generator: Tu instancia de F5TTS
        reference_audio: Path al audio de referencia
        apply_postprocess: Si aplicar correcci√≥n exhaustiva (Fase 2)
        save_report: Si guardar reporte de procesamiento

    Returns:
        Tuple de (segmentos individuales, audio concatenado final)
    """

    # Crear orquestador
    orchestrator = ProsodyOrchestrator(f5_generator)

    # Generar con mejoras pros√≥dicas
    audio_segments, report = orchestrator.generate_with_prosody(
        texts,
        apply_postprocess=apply_postprocess,
        reference_audio=reference_audio
    )

    # Concatenar inteligentemente
    final_audio = smart_concatenate(audio_segments)

    # Guardar reporte si se solicita
    if save_report:
        export_prosody_report(report, 'prosody_enhancement_report.json')

    # Mostrar resumen
    print("\n" + "="*50)
    print("üìä RESUMEN DE MEJORA PROS√ìDICA")
    print("="*50)
    print(f"‚úÖ Frases procesadas: {report['segments_generated']}")
    print(f"üìù Hints aplicados: {report['hints_applied']}")

    if 'problems_found' in report:
        print(f"üîç Problemas detectados: {report['problems_found']}")
        print(f"üîß Problemas corregidos: {report.get('segments_fixed', 0)}")

    print(f"‚è±Ô∏è Tiempo total: {report['total_time']:.1f} segundos")
    print(f"‚ö° Promedio por frase: {report['total_time']/len(texts):.2f} segundos")

    return audio_segments, final_audio


if __name__ == "__main__":
    # Ejemplo de uso
    print("Sistema de Mejora Pros√≥dica para F5-TTS")
    print("Basado en arquitectura vocal documentada")
    print("-" * 50)

    # Textos de ejemplo
    example_texts = [
        "El viento nocturno atravesaba los callejones de la ciudad antigua.",
        "Las piedras centenarias parec√≠an susurrar historias olvidadas.",
        "¬øAcaso no era esa la magia del lugar?",
        "Pero esa noche era diferente.",
        "Algo indefinible vibraba en el aire.",
        "Los gatos se agrupaban en los tejados como centinelas silenciosos.",
        "Al amanecer, cuando los primeros rayos doraron las c√∫pulas.",
        "La ciudad exhal√≥ un suspiro colectivo.",
        "Todo se disolvi√≥ con la niebla matutina."
    ]

    # Simular generaci√≥n
    orchestrator = ProsodyOrchestrator()
    segments, report = orchestrator.generate_with_prosody(
        example_texts,
        apply_postprocess=False  # Solo Fase 1 para demo
    )

    print("\n‚úÖ Demo completada. Sistema listo para integraci√≥n.")