#!/usr/bin/env python3
"""
====================================================================================================
GENERADOR BASE - ESTRUCTURA COMPLEJA MEJORADA (v3)
====================================================================================================

Descripci√≥n:
    Clase base para la generaci√≥n de audio con F5-TTS. Proporciona la infraestructura
    fundamental para la s√≠ntesis de voz con clonaci√≥n vocal y procesamiento por frases.

Funcionamiento:
    Sistema aut√≥nomo que:
    - Busca autom√°ticamente archivos .wav de referencia en el directorio
    - Lee texto desde archivos predefinidos (texto.txt, ejemplo_texto.txt, etc.)
    - Genera audio segmentado por frases con crossfade
    - Organiza resultados en estructura de directorios con timestamp

Arquitectura de Salida:
    generaciones/
    ‚îú‚îÄ‚îÄ YYYY-MM-DD_HH-MM-SS_estructura_compleja/
    ‚îÇ   ‚îú‚îÄ‚îÄ referencia_1/
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ estructura_compleja_mejorada_nfeXX.wav  # Audio final
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ frase_01.wav                            # Frases individuales
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ frase_02.wav
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ...
    ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ analisis_tecnico.txt                    # M√©tricas t√©cnicas
    ‚îÇ   ‚îî‚îÄ‚îÄ resumen_ejecucion.txt                       # Resumen global

Caracter√≠sticas T√©cnicas:
    - Segmentaci√≥n autom√°tica de texto en frases
    - Concatenaci√≥n con crossfade configurable
    - Normalizaci√≥n de volumen por frase
    - Filtrado opcional de DC offset
    - Optimizaci√≥n de par√°metros F5-TTS por contexto
    - Gesti√≥n de memoria CUDA optimizada

Par√°metros de Generaci√≥n:
    - nfe_step: Pasos de flow matching (default: 32)
    - cfg_strength: Fuerza de classifier-free guidance (default: 2.0)
    - sway_sampling_coef: Coeficiente de muestreo sway (default: -1.0)
    - speed: Velocidad de habla relativa (default: 1.0)

Autor: Sistema base F5-TTS
Versi√≥n: 3.0
====================================================================================================
"""

import os
import sys
from pathlib import Path
import librosa
import soundfile as sf
import numpy as np
from tqdm import tqdm
import torch
from f5_tts.api import F5TTS
from scipy.signal import butter, filtfilt
import time
import warnings
import logging
import re
from datetime import datetime

# Suprimir warnings de librer√≠as externas
warnings.filterwarnings("ignore")

# ====================================================================================================
# CONFIGURACI√ìN DE ENTORNO
# ====================================================================================================
# Configuraci√≥n CUDA para orden consistente de dispositivos
os.environ['CUDA_DEVICE_ORDER'] = 'PCI_BUS_ID'
os.environ['CUDA_VISIBLE_DEVICES'] = '0'

# Inicializar CUDA correctamente
if torch.cuda.is_available():
    torch.cuda.init()
    print(f"üéÆ CUDA inicializada: {torch.cuda.get_device_name(0)}")
else:
    print("‚ö†Ô∏è CUDA no disponible, usando CPU")

# Configurar logging para an√°lisis t√©cnico
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


class EstructuraComplejaMejorada:
    def __init__(self, model_path="./model_943000.pt", texto_usuario=None, session_dir=None):
        self.model_path = model_path
        self.device = "cuda" if torch.cuda.is_available() else "cpu"
        self.sample_rate = 24000

        # Configuraci√≥n optimizada para contenido provocativo
        self.crossfade_duration = 0.15     # 150ms de crossfade
        self.base_pause_duration = 0.125   # Pausas base entre frases
        self.paragraph_pause = 0.25        # Pausas entre p√°rrafos

        # CONFIGURACI√ìN ANTI-TRUNCAMIENTO MEJORADA
        self.nfe_steps = 64  # SIEMPRE 64 para m√°xima calidad
        self.sway_sampling_coef = -1.0  # Bias hacia t‚Üí0 para mejor alineaci√≥n
        self.cfg_strength = 2.0  # Balance estabilidad/expresividad
        self.speed = 0.95  # Ligeramente m√°s lento para completitud

        # Par√°metros de validaci√≥n anti-truncamiento
        self.max_validation_attempts = None  # None = reintentos ilimitados hasta validaci√≥n exitosa
        self.fallback_after_attempts = 50    # Despu√©s de 50 intentos, usar el mejor candidato
        self.quality_metrics = {
            'min_duration_ratio': 0.7,
            'max_duration_ratio': 1.5,
            'min_energy_threshold': 0.001,
            'max_silence_ratio': 0.25,
            'pitch_stability_threshold': 0.05
        }

        # Caracter√≠sticas espec√≠ficas del espa√±ol para anti-truncamiento
        self.problematic_finals = ['s', 'd', 'r', 'n', 'l']
        self.sinalefa_patterns = [
            r'[aeiou√°√©√≠√≥√∫]\s+[aeiou√°√©√≠√≥√∫]',  # vocales entre palabras
            r'[aeiou]n\s+[aeiou]',
            r'[aeiou]r\s+[aeiou]',
        ]

        # Directorios din√°micos (se establecen por referencia)
        self.script_dir = Path(__file__).parent.resolve()
        self.reference_dir = self.script_dir  # Referencias en el mismo directorio
        self.reference_file = None

        # Directorio de sesi√≥n con timestamp
        self.session_dir = session_dir if session_dir else self.create_session_directory()
        self.output_dir = None  # Se define por referencia

        # Lista de frases del discurso provocativo (default)
        self.frases = [
            "Eres una piba, son las 11 de la noche y est√°s en el sof√°.",
            "Tu tel√©fono vibra.",
            "Es un audio de WhatsApp de una conocida del trabajo.",
            "Veintisiete a√±os, como la mayor√≠a del grupo.",
            "La voz le tiembla ligeramente.",
            "T√≠a, es que ya s√© c√≥mo identificar a un machista.",
            "Es s√∫per f√°cil.",
            "Cuando hay una movida entre un t√≠o y una t√≠a, si se pone del lado del t√≠o... ah√≠ lo tienes.",
            "Es un machista."
        ]

        # Si el usuario proporciona texto, procesarlo correctamente
        if texto_usuario is not None and isinstance(texto_usuario, str):
            texto_limpio = texto_usuario.strip()
            if texto_limpio:
                partes = re.split(r'(?<!\.)\.(?!\.)', texto_limpio)
                frases_usuario = []
                for parte in partes:
                    parte_limpia = parte.strip()
                    if parte_limpia:
                        if not parte_limpia.endswith('.') and not parte_limpia.endswith('!') and not parte_limpia.endswith('?'):
                            parte_limpia += '.'
                        frases_usuario.append(parte_limpia)

                if len(frases_usuario) > 0:
                    self.frases = frases_usuario
                    print(f"üìù Texto dividido en {len(self.frases)} frases:")
                    for idx, frase in enumerate(self.frases, 1):
                        print(f"   {idx}. {frase[:60]}{'...' if len(frase) > 60 else ''}")

        # Marcadores de p√°rrafos y pausas especiales
        self.paragraph_breaks = [1, 3, 7, 10]

        # FUSI√ìN DE FRASES M√çNIMAS: unir frases cortas (<4 palabras) con la anterior si no excede longitud
        self._merge_minimum_phrases(min_words=4, max_merged_chars=160)

        print(f"üé≠ Generador Mejorado v3 - Multi-referencia con Timestamp")
        print(f"üì± Device: {self.device}")
        print(f"üéØ Frases por discurso: {len(self.frases)}")
        print(f"üìÅ Sesi√≥n: {self.session_dir.name}")
        print(f"üî¨ NFE Steps: {self.nfe_steps} (m√°xima calidad)")
        print(f"üõ°Ô∏è Validaci√≥n anti-truncamiento: ACTIVADA (reintentos ilimitados)")
        print(f"üõü Fallback despu√©s de {self.fallback_after_attempts} intentos")
        print(f"‚è±Ô∏è Pausas configuradas: base={self.base_pause_duration}s, p√°rrafo={self.paragraph_pause}s")
        print(f"üîó Crossfade: {self.crossfade_duration*1000:.0f}ms")

        self.f5tts = None  # Se inicializa bajo demanda
        self.session_stats = {
            'inicio': datetime.now(),
            'referencias_procesadas': 0,
            'total_referencias': 0,
            'errores': [],
            'tiempo_total': 0
        }

    def create_session_directory(self):
        """Crea un directorio √∫nico para esta sesi√≥n con timestamp"""
        timestamp = datetime.now().strftime("%Y-%m-%d_%H-%M-%S")
        session_name = f"{timestamp}_estructura_compleja"
        
        generaciones_dir = self.script_dir / "generaciones"
        generaciones_dir.mkdir(exist_ok=True)
        
        session_dir = generaciones_dir / session_name
        session_dir.mkdir(exist_ok=True)
        
        return session_dir

    def initialize_model(self):
        """Inicializa el modelo F5-TTS si no est√° ya cargado"""
        if getattr(self, 'f5tts', None) is not None:
            return

        print("üîÑ Cargando modelo F5-TTS...")
        
        # Asegurar que CUDA est√© disponible
        if self.device == "cuda" and not torch.cuda.is_available():
            print("‚ö†Ô∏è CUDA no disponible, cambiando a CPU")
            self.device = "cpu"
        
        try:
            # Configurar torch.load para usar weights_only=False
            # Nota: evitamos 'import torch.serialization' aqu√≠ para no crear una variable local 'torch'
            import importlib
            importlib.import_module('torch.serialization')
            original_load = torch.load
            
            def safe_load(f, map_location=None, **kwargs):
                if 'weights_only' not in kwargs:
                    kwargs['weights_only'] = False
                if map_location is None and self.device == "cuda":
                    map_location = "cuda:0"
                elif map_location is None:
                    map_location = "cpu"
                return original_load(f, map_location=map_location, **kwargs)
            
            torch.load = safe_load
            
            self.f5tts = F5TTS(
                model_type="F5-TTS",
                ckpt_file=str(self.model_path),
                vocab_file="./vocab.txt",
                ode_method="euler",
                use_ema=True,
                vocoder_name="vocos",
                device=self.device
            )
            
            # Restaurar torch.load original
            torch.load = original_load
            
            print(f"‚úÖ Modelo cargado exitosamente en {self.device.upper()}")
            
            if self.device == "cuda":
                print(f"üéÆ GPU Memory: {torch.cuda.get_device_properties(0).total_memory/1024**3:.1f}GB")
                
        except Exception as e:
            print(f"‚ùå Error cargando modelo: {e}")
            
            # Intentar con CPU como fallback
            if self.device == "cuda":
                print("üîÑ Intentando con CPU como fallback...")
                self.device = "cpu"
                try:
                    torch.load = safe_load
                    self.f5tts = F5TTS(
                        model_type="F5-TTS",
                        ckpt_file=str(self.model_path),
                        vocab_file="../data/my_speak_pinyin/vocab.txt",
                        ode_method="euler",
                        use_ema=True,
                        vocoder_name="vocos",
                        device=self.device
                    )
                    torch.load = original_load
                    print("‚úÖ Modelo cargado en CPU (fallback)")
                    return
                except Exception as e2:
                    torch.load = original_load
                    print(f"‚ùå Error tambi√©n en CPU: {e2}")
            
            self.session_stats['errores'].append(f"Error cargando modelo: {e}")
            sys.exit(1)

    def set_reference(self, ref_path: Path):
        """Configura la referencia actual y su carpeta de salida."""
        self.reference_dir = ref_path.parent
        self.reference_file = ref_path.name

        # Subcarpeta por referencia dentro de la sesi√≥n
        ref_stem = ref_path.stem
        self.output_dir = self.session_dir / ref_stem
        self.output_dir.mkdir(parents=True, exist_ok=True)

    def detect_spanish_features(self, text):
        analysis = {
            'sinalefas': [],
            'problematic_finals': [],
            'total_chars': len(text),
            'estimated_syllables': 0,
            'complexity_score': 0.0
        }

        # Detectar sinalefas
        for pattern in self.sinalefa_patterns:
            matches = list(re.finditer(pattern, text.lower()))
            analysis['sinalefas'].extend(matches)

        # Detectar consonantes finales problem√°ticas
        words = re.findall(r'\b\w+\b', text.lower())
        for word in words:
            if word and word[-1] in self.problematic_finals:
                analysis['problematic_finals'].append(word)

        # Estimaci√≥n de s√≠labas
        vowel_groups = len(re.findall(r'[aeiou√°√©√≠√≥√∫]+', text.lower()))
        analysis['estimated_syllables'] = max(vowel_groups, len(text.split()) * 2)

        # Score de complejidad
        sinalefa_factor = len(analysis['sinalefas']) * 0.1
        finals_factor = len(analysis['problematic_finals']) * 0.02
        analysis['complexity_score'] = min(1.0, sinalefa_factor + finals_factor)

        return analysis

    def validate_audio_anti_truncation(self, audio, text, attempt_num=1):
        if audio is None or len(audio) == 0:
            return False, "Audio vac√≠o"

        try:
            duration = len(audio) / self.sample_rate
            spanish_features = self.detect_spanish_features(text)

            # Duraci√≥n esperada (espa√±ol ~8-15 chars/s)
            expected_min = len(text) / 15 * self.quality_metrics['min_duration_ratio']
            expected_max = len(text) / 8 * self.quality_metrics['max_duration_ratio']

            # Ajustar por complejidad
            if spanish_features['complexity_score'] > 0.3:
                expected_min *= 0.9
                expected_max *= 1.2

            if duration < expected_min:
                return False, f"Duraci√≥n insuficiente: {duration:.2f}s < {expected_min:.2f}s (posible truncamiento)"
            if duration > expected_max:
                return False, f"Duraci√≥n excesiva: {duration:.2f}s > {expected_max:.2f}s"

            # Energ√≠a m√≠nima
            rms = np.sqrt(np.mean(audio**2))
            if rms < self.quality_metrics['min_energy_threshold']:
                return False, f"Energ√≠a insuficiente: {rms:.6f}"

            # Extremos no cortados
            window_samples = int(0.05 * self.sample_rate)
            if len(audio) > window_samples * 2:
                inicio_energy = np.mean(audio[:window_samples]**2)
                final_energy = np.mean(audio[-window_samples:]**2)
                avg_energy = np.mean(audio**2)
                if inicio_energy > avg_energy * 4 or final_energy > avg_energy * 4:
                    return False, f"Posible audio cortado en extremos"

            # Consonantes finales problem√°ticas
            has_problematic_finals = any(text.lower().strip().endswith(c) for c in self.problematic_finals)
            if has_problematic_finals:
                final_portion = audio[-int(0.2 * self.sample_rate):]
                try:
                    final_f0 = librosa.yin(final_portion, fmin=75, fmax=400, sr=self.sample_rate)
                    final_f0_valid = final_f0[final_f0 > 0]
                    if len(final_f0_valid) < 3:
                        return False, f"Posible consonante final cortada (texto termina en '{text.lower().strip()[-1]}')"
                except Exception:
                    pass

            # Silencio interno
            frame_length = int(0.025 * self.sample_rate)
            hop_length = frame_length // 4
            rms_frames = librosa.feature.rms(y=audio, frame_length=frame_length, hop_length=hop_length)[0]
            silent_frames = np.sum(rms_frames < self.quality_metrics['min_energy_threshold'])
            silence_ratio = silent_frames / len(rms_frames) if len(rms_frames) > 0 else 0
            if silence_ratio > self.quality_metrics['max_silence_ratio']:
                return False, f"Exceso de silencio interno: {silence_ratio:.1%}"

            # Estabilidad del pitch
            try:
                f0 = librosa.yin(audio, fmin=75, fmax=400, sr=self.sample_rate)
                f0_valid = f0[f0 > 0]
                if len(f0_valid) > 10:
                    f0_jumps = np.abs(np.diff(f0_valid))
                    extreme_jumps = np.sum(f0_jumps > 50)
                    instability = extreme_jumps / len(f0_valid) if len(f0_valid) > 0 else 0
                    if instability > self.quality_metrics['pitch_stability_threshold']:
                        return False, f"Pitch inestable: {extreme_jumps} saltos extremos ({instability:.1%})"
            except Exception:
                pass

            # Verificaci√≥n espec√≠fica de sinalefas
            if len(spanish_features['sinalefas']) > 0:
                try:
                    stft = librosa.stft(audio, hop_length=512)
                    spectral_centroids = librosa.feature.spectral_centroid(S=np.abs(stft), sr=self.sample_rate)[0]
                    centroid_diff = np.abs(np.diff(spectral_centroids))
                    extreme_drops = np.sum(centroid_diff > np.std(centroid_diff) * 3)
                    drop_ratio = extreme_drops / len(centroid_diff) if len(centroid_diff) > 0 else 0
                    if drop_ratio > 0.1:
                        return False, f"Posibles sinalefas cortadas: {extreme_drops} ca√≠das espectrales"
                except Exception:
                    pass

            return True, f"‚úÖ Validaci√≥n exitosa (intento {attempt_num})"

        except Exception as e:
            logger.error(f"Error en validaci√≥n: {e}")
            return False, f"Error en validaci√≥n: {e}"

    def generate_single_phrase_with_validation(self, text, phrase_idx):
        ref_path = self.reference_dir / self.reference_file

        best_candidate = None  # (audio, score)
        attempt = 1

        # MICRO-AJUSTE PARA FRASES CORTAS NO FUSIONADAS
        import re as _re_short
        # Limpieza simple de puntuaci√≥n conflictiva antes de enviar al motor
        text = self._clean_text_simple(text)
        num_words = len(_re_short.findall(r'\b\w+\b', text))
        short_phrase = (num_words < 7) or (len(text) < 35)
        # Guardar par√°metros originales
        original_nfe = self.nfe_steps
        original_sway = self.sway_sampling_coef
        original_speed = self.speed
        try:
            if short_phrase:
                # Aplicar par√°metros m√°s estables SOLO para esta frase
                self.nfe_steps = 28
                self.sway_sampling_coef = -0.3
                self.speed = 0.95

            while True:
                try:
                    if attempt > 1:
                        if attempt % 10 == 0:
                            print(f"    üîÑ Reintento {attempt}/‚àû")
                    else:
                        print(f"  üéØ Generando frase {phrase_idx + 1}: '{text[:50]}...'")

                    wav, sr, spect = self.f5tts.infer(
                        ref_file=str(ref_path),
                        ref_text="",
                        gen_text=text,
                        nfe_step=self.nfe_steps,
                        sway_sampling_coef=self.sway_sampling_coef,
                        cfg_strength=self.cfg_strength,
                        speed=self.speed,
                        remove_silence=False,
                        seed=-1
                    )

                    if wav is None or len(wav) == 0:
                        print(f"    ‚ùå Audio vac√≠o en intento {attempt}")
                        attempt += 1
                        continue

                    is_valid, validation_msg = self.validate_audio_anti_truncation(wav, text, attempt)

                    if is_valid:
                        if np.max(np.abs(wav)) > 0:
                            wav = wav / np.max(np.abs(wav)) * 0.9

                        phrase_path = self.output_dir / f"frase_{phrase_idx+1:02d}.wav"
                        sf.write(phrase_path, wav, sr)

                        print(f"    {validation_msg}")
                        return wav
                    else:
                        print(f"    ‚ùå Validaci√≥n fall√≥: {validation_msg}")

                        quality_score = self.evaluate_audio_quality(wav, text)
                        if best_candidate is None or quality_score < best_candidate[1]:
                            best_candidate = (wav.copy(), quality_score)

                        if self.fallback_after_attempts and attempt >= self.fallback_after_attempts:
                            print(f"    ‚ö†Ô∏è Usando mejor candidato tras {attempt} intentos (fallback)")
                            wav = best_candidate[0]
                            if np.max(np.abs(wav)) > 0:
                                wav = wav / np.max(np.abs(wav)) * 0.9
                            phrase_path = self.output_dir / f"frase_{phrase_idx+1:02d}.wav"
                            sf.write(phrase_path, wav, sr)
                            return wav

                except KeyboardInterrupt:
                    raise
                except Exception as e:
                    print(f"    ‚ùå Error en intento {attempt}: {e}")
                    # Manejo especial: tratar el error de interpolaci√≥n del motor con fallbacks espec√≠ficos
                    if 't must be strictly increasing or decreasing' in str(e):
                        print("    ‚ö†Ô∏è Activando fallbacks para frase de riesgo‚Ä¶")
                        # 1) Reintento con extensi√≥n neutra y par√°metros estables
                        ext_text = self._extend_text_for_engine(text)
                        try:
                            wav_ext, sr, _ = self.f5tts.infer(
                                ref_file=str(ref_path),
                                ref_text="",
                                gen_text=ext_text,
                                nfe_step=28,
                                sway_sampling_coef=-0.3,
                                cfg_strength=self.cfg_strength,
                                speed=0.95,
                                remove_silence=False,
                                seed=-1
                            )
                            if wav_ext is not None and len(wav_ext) > 0:
                                valid_ext, msg_ext = self.validate_audio_anti_truncation(wav_ext, ext_text, attempt)
                                if valid_ext:
                                    if np.max(np.abs(wav_ext)) > 0:
                                        wav_ext = wav_ext / np.max(np.abs(wav_ext)) * 0.9
                                    phrase_path = self.output_dir / f"frase_{phrase_idx+1:02d}.wav"
                                    sf.write(phrase_path, wav_ext, sr)
                                    print(f"    ‚úÖ Fallback (extensi√≥n) exitoso: {msg_ext}")
                                    return wav_ext
                        except Exception as e1:
                            print(f"    ‚ö†Ô∏è Fallback extensi√≥n fall√≥: {e1}")
                        # 2) Reintento dividiendo en 2 partes y concatenando
                        try:
                            parts = self._split_text_for_engine_short(text)
                            if len(parts) > 1:
                                segs = []
                                for pi, ptxt in enumerate(parts, 1):
                                    ptxt_clean = self._clean_text_simple(ptxt)
                                    wav_p, sr, _ = self.f5tts.infer(
                                        ref_file=str(ref_path),
                                        ref_text="",
                                        gen_text=ptxt_clean,
                                        nfe_step=28,
                                        sway_sampling_coef=-0.3,
                                        cfg_strength=self.cfg_strength,
                                        speed=0.95,
                                        remove_silence=False,
                                        seed=-1
                                    )
                                    if wav_p is not None and len(wav_p) > 0:
                                        if np.max(np.abs(wav_p)) > 0:
                                            wav_p = wav_p / np.max(np.abs(wav_p)) * 0.9
                                        segs.append(wav_p)
                                if segs:
                                    # Concatenar con crossfade igual potencia si hay 2 segmentos
                                    combined = segs[0]
                                    fade_samples = int(self.crossfade_duration * self.sample_rate)
                                    for s in segs[1:]:
                                        combined = self.apply_equal_power_crossfade(combined, s, fade_samples)
                                    valid_comb, msg_comb = self.validate_audio_anti_truncation(combined, text, attempt)
                                    if valid_comb:
                                        phrase_path = self.output_dir / f"frase_{phrase_idx+1:02d}.wav"
                                        sf.write(phrase_path, combined, self.sample_rate)
                                        print(f"    ‚úÖ Fallback (divisi√≥n) exitoso: {msg_comb}")
                                        return combined
                        except Exception as e2:
                            print(f"    ‚ö†Ô∏è Fallback divisi√≥n fall√≥: {e2}")
                        # Si fallan fallbacks, detener como cr√≠tico
                        print("    üõë Error cr√≠tico del motor detectado: deteniendo y liberando GPU‚Ä¶")
                        # Guardar estado de reanudaci√≥n
                        try:
                            import json
                            from pathlib import Path as _Path
                            resume_state = {
                                'context': 'estructura_compleja_v3',
                                'phrase_idx': phrase_idx,
                                'reference_file': str(self.reference_dir / self.reference_file),
                                'session_dir': str(self.output_dir),
                                'device': self.device,
                            }
                            _Path('resume_state.json').write_text(json.dumps(resume_state, indent=2), encoding='utf-8')
                        except Exception:
                            pass
                        self._shutdown_gpu()
                        raise SystemExit("ENGINE_STRICT_T_ERROR")

                    if attempt >= 10 and best_candidate is not None:
                        print(f"    ‚ö†Ô∏è Usando mejor candidato tras m√∫ltiples errores")
                        wav = best_candidate[0]
                        if np.max(np.abs(wav)) > 0:
                            wav = wav / np.max(np.abs(wav)) * 0.9
                        return wav

                attempt += 1
                time.sleep(0.5)
        finally:
            # Restaurar par√°metros originales
            self.nfe_steps = original_nfe
            self.sway_sampling_coef = original_sway
            self.speed = original_speed

    def evaluate_audio_quality(self, audio, text):
        try:
            duration = len(audio) / self.sample_rate
            spanish_features = self.detect_spanish_features(text)

            expected_min = len(text) / 15 * self.quality_metrics['min_duration_ratio']
            expected_max = len(text) / 8 * self.quality_metrics['max_duration_ratio']
            if spanish_features['complexity_score'] > 0.3:
                expected_min *= 0.9
                expected_max *= 1.2
            expected_mid = (expected_min + expected_max) / 2

            rms = np.sqrt(np.mean(audio**2))

            frame_length = int(0.025 * self.sample_rate)
            hop_length = frame_length // 4
            rms_frames = librosa.feature.rms(y=audio, frame_length=frame_length, hop_length=hop_length)[0]
            silence_ratio = np.sum(rms_frames < self.quality_metrics['min_energy_threshold']) / len(rms_frames)

            duration_penalty = abs(duration - expected_mid) / expected_mid
            energy_penalty = max(0, (self.quality_metrics['min_energy_threshold'] - rms) / self.quality_metrics['min_energy_threshold'])
            silence_penalty = max(0, silence_ratio - self.quality_metrics['max_silence_ratio'])

            score = 2.0 * duration_penalty + 1.0 * energy_penalty + 1.0 * silence_penalty

            return score
        except Exception:
            return 999.0

    def add_natural_pause(self, duration_seconds):
        silence_samples = int(duration_seconds * self.sample_rate)
        pause = np.zeros(silence_samples, dtype=np.float32)

        noise_level = 0.0001
        pink_noise = np.random.normal(0, noise_level, silence_samples)

        b, a = butter(1, 0.1, btype='low')
        pink_noise = filtfilt(b, a, pink_noise)

        pause += pink_noise.astype(np.float32)

        return pause

    def apply_equal_power_crossfade(self, audio1, audio2, fade_samples):
        if len(audio1) < fade_samples or len(audio2) < fade_samples:
            return np.concatenate([audio1, audio2])

        t = np.linspace(0, np.pi/2, fade_samples)
        fade_out = np.cos(t)
        fade_in = np.sin(t)

        audio1_faded = audio1.copy()
        audio1_faded[-fade_samples:] *= fade_out

        audio2_faded = audio2.copy()
        audio2_faded[:fade_samples] *= fade_in

        overlap = audio1_faded[-fade_samples:] + audio2_faded[:fade_samples]

        result = np.concatenate([
            audio1_faded[:-fade_samples],
            overlap,
            audio2_faded[fade_samples:]
        ])

        return result

    def concatenate_with_dramatic_transitions(self, generated_audios):
        print("üé≠ Aplicando transiciones...")

        if not generated_audios:
            print("‚ùå No hay audios para concatenar")
            return None

        final_audio = generated_audios[0][1].copy()
        fade_samples = int(self.crossfade_duration * self.sample_rate)

        for i in range(1, len(generated_audios)):
            phrase_idx, current_audio = generated_audios[i]

            pause_duration = self.base_pause_duration
            natural_pause = self.add_natural_pause(pause_duration)
            final_audio = np.concatenate([final_audio, natural_pause])

            final_audio = self.apply_equal_power_crossfade(final_audio, current_audio, fade_samples)

            print(f"    üîó Transici√≥n aplicada: frase {phrase_idx + 1}")

        final_audio = self.apply_professional_normalization(final_audio)

        return final_audio

    def apply_professional_normalization(self, audio):
        current_rms = np.sqrt(np.mean(audio**2))
        if current_rms > 0:
            target_rms = 10**(-20 / 20)
            audio = audio * (target_rms / current_rms)

        peak = np.max(np.abs(audio))
        peak_limit = 10**(-3 / 20)
        if peak > peak_limit:
            audio = audio * (peak_limit / peak)

        return audio.astype(np.float32)

    def _shutdown_gpu(self):
        """Libera memoria GPU (sin reset para no afectar GPU primaria)."""
        try:
            if self.device == 'cuda':
                torch.cuda.empty_cache()
                torch.cuda.synchronize()
                torch.cuda.ipc_collect()
        except Exception as e:
            print(f"    ‚ö†Ô∏è No se pudo liberar memoria GPU: {e}")

    def generate_all_phrases(self):
        print("üé≠ Iniciando generaci√≥n con validaci√≥n anti-truncamiento...")
        print(f"   ‚Ä¢ NFE Steps: {self.nfe_steps}")
        print(f"   ‚Ä¢ Reintentos: ilimitados hasta validaci√≥n exitosa")
        print(f"   ‚Ä¢ Fallback despu√©s de {self.fallback_after_attempts} intentos")
        print(f"   ‚Ä¢ Pausas base: {self.base_pause_duration}s")
        print(f"   ‚Ä¢ Crossfade: {self.crossfade_duration*1000:.0f}ms")

        generated_audios = []
        validation_stats = {'exitosas': 0, 'con_reintentos': 0, 'fallidas': 0}

        for i, frase in enumerate(tqdm(self.frases, desc="Generando con anti-truncamiento")):
            audio = self.generate_single_phrase_with_validation(frase, i)
            if audio is not None:
                generated_audios.append((i, audio))
                validation_stats['exitosas'] += 1
            else:
                print(f"    ‚ö†Ô∏è Frase {i+1} fall√≥ completamente")
                validation_stats['fallidas'] += 1

        print(f"\nüìä Estad√≠sticas de validaci√≥n:")
        print(f"   ‚Ä¢ Exitosas: {validation_stats['exitosas']}/{len(self.frases)}")
        print(f"   ‚Ä¢ Fallidas: {validation_stats['fallidas']}")

        return generated_audios

    def save_technical_analysis(self, final_audio, generated_count):
        analysis_path = self.output_dir / "analisis_tecnico.txt"

        with open(analysis_path, 'w', encoding='utf-8') as f:
            f.write("AN√ÅLISIS T√âCNICO - ESTRUCTURA COMPLEJA MEJORADA (v3)\n")
            f.write("=" * 60 + "\n\n")

            f.write("CONFIGURACI√ìN ANTI-TRUNCAMIENTO:\n")
            f.write(f"- NFE Steps: {self.nfe_steps} (m√°xima calidad)\n")
            f.write(f"- Sway Sampling: {self.sway_sampling_coef}\n")
            f.write(f"- CFG Strength: {self.cfg_strength}\n")
            f.write(f"- Speed: {self.speed}\n")
            f.write(f"- Max reintentos: ilimitados (fallback tras {self.fallback_after_attempts})\n\n")

            duration = len(final_audio) / self.sample_rate
            rms = np.sqrt(np.mean(final_audio**2))
            peak = np.max(np.abs(final_audio))

            f.write("AN√ÅLISIS DE AUDIO:\n")
            f.write(f"- Duraci√≥n: {duration:.2f} segundos\n")
            f.write(f"- RMS Level: {20*np.log10(rms):.1f} dBFS\n")
            f.write(f"- Peak Level: {20*np.log10(peak):.1f} dBFS\n")
            f.write(f"- Dynamic Range: {20*np.log10(peak/(rms+1e-10)):.1f} dB\n\n")

            f.write(f"FRASES PROCESADAS: {generated_count}/{len(self.frases)}\n\n")

            for i, frase in enumerate(self.frases, 1):
                features = self.detect_spanish_features(frase)
                f.write(f"{i}. \"{frase}\"\n")
                f.write(f"   - S√≠labas estimadas: {features['estimated_syllables']}\n")
                f.write(f"   - Complejidad: {features['complexity_score']:.2f}\n")
                f.write(f"   - Consonantes finales problem√°ticas: {features['problematic_finals']}\n\n")

        print(f"üìÑ An√°lisis t√©cnico guardado: {analysis_path.name}")

    def generate_complete_speech_for_reference(self, ref_path: Path):
        print("üé≠ Iniciando generaci√≥n mejorada con anti-truncamiento")
        print("=" * 65)

        self.set_reference(ref_path)

        print(f"üéôÔ∏è Referencia: {self.reference_file}")
        print(f"üìÇ Carpeta de salida: {self.output_dir}")

        start_time = time.time()

        if not ref_path.exists():
            print(f"‚ùå No se encuentra la referencia: {ref_path}")
            error_msg = f"Referencia no encontrada: {ref_path}"
            self.session_stats['errores'].append(error_msg)
            return

        generated_audios = self.generate_all_phrases()

        if not generated_audios:
            print("‚ùå No se pudieron generar audios")
            error_msg = f"No se pudieron generar audios para {self.reference_file}"
            self.session_stats['errores'].append(error_msg)
            return

        print(f"‚úÖ Generadas {len(generated_audios)} de {len(self.frases)} frases")

        final_speech = self.concatenate_with_dramatic_transitions(generated_audios)

        if final_speech is None:
            print("‚ùå Error en la concatenaci√≥n")
            error_msg = f"Error en concatenaci√≥n para {self.reference_file}"
            self.session_stats['errores'].append(error_msg)
            return

        output_filename = "estructura_compleja_mejorada_nfe64.wav"
        output_path = self.output_dir / output_filename
        sf.write(output_path, final_speech, self.sample_rate)

        self.save_technical_analysis(final_speech, len(generated_audios))

        end_time = time.time()
        duration_minutes = len(final_speech) / self.sample_rate / 60
        file_size_mb = output_path.stat().st_size / (1024 * 1024)
        generation_time = end_time - start_time

        print("\nüéä ¬°Generaci√≥n completada exitosamente!")
        print("=" * 65)
        print(f"üìÅ Archivo guardado: {output_path.name}")
        print(f"‚è±Ô∏è Duraci√≥n del audio: {duration_minutes:.2f} minutos")
        print(f"üíæ Tama√±o del archivo: {file_size_mb:.1f} MB")
        print(f"üéØ Frases incluidas: {len(generated_audios)}")
        print(f"üéôÔ∏è Referencia utilizada: {self.reference_file}")
        print(f"üîÑ Tiempo de generaci√≥n: {generation_time:.1f} segundos")
        print(f"‚ö° Promedio por frase: {generation_time/len(generated_audios):.1f} segundos")

        # Actualizar estad√≠sticas de sesi√≥n
        self.session_stats['referencias_procesadas'] += 1
        self.session_stats['tiempo_total'] += generation_time

        print(f"\nüîß Configuraci√≥n t√©cnica:")
        print(f"   ‚Ä¢ NFE Steps: {self.nfe_steps} (m√°xima calidad)")
        print(f"   ‚Ä¢ Sway Sampling: {self.sway_sampling_coef}")
        print(f"   ‚Ä¢ CFG Strength: {self.cfg_strength}")
        print(f"   ‚Ä¢ Speed: {self.speed}")
        print(f"   ‚Ä¢ Sample rate: {self.sample_rate} Hz")
        print(f"   ‚Ä¢ Crossfade: {self.crossfade_duration * 1000:.0f}ms")
        print(f"   ‚Ä¢ Pausas base: {self.base_pause_duration}s")
        print(f"   ‚Ä¢ Pausas p√°rrafo: {self.paragraph_pause}s")
        print(f"   ‚Ä¢ Validaci√≥n anti-truncamiento: ACTIVADA")
        print(f"   ‚Ä¢ Reintentos: ilimitados (fallback tras {self.fallback_after_attempts} intentos)")
        print(f"   ‚Ä¢ Normalizaci√≥n: -20dBFS target, -3dB peak")

    def save_session_summary(self):
        """Guarda un resumen de toda la sesi√≥n"""
        summary_path = self.session_dir / "resumen_ejecucion.txt"
        fin = datetime.now()
        
        with open(summary_path, 'w', encoding='utf-8') as f:
            f.write("RESUMEN DE EJECUCI√ìN - GENERADOR ESTRUCTURA COMPLEJA v3\n")
            f.write("=" * 70 + "\n\n")
            
            f.write("INFORMACI√ìN DE SESI√ìN:\n")
            f.write(f"- Inicio: {self.session_stats['inicio'].strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"- Fin: {fin.strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"- Duraci√≥n total: {(fin - self.session_stats['inicio']).total_seconds():.1f} segundos\n")
            f.write(f"- Directorio de sesi√≥n: {self.session_dir.name}\n\n")
            
            f.write("ESTAD√çSTICAS DE PROCESAMIENTO:\n")
            f.write(f"- Referencias totales: {self.session_stats['total_referencias']}\n")
            f.write(f"- Referencias procesadas: {self.session_stats['referencias_procesadas']}\n")
            f.write(f"- Tasa de √©xito: {(self.session_stats['referencias_procesadas']/max(1,self.session_stats['total_referencias']))*100:.1f}%\n")
            f.write(f"- Tiempo total de generaci√≥n: {self.session_stats['tiempo_total']:.1f} segundos\n")
            f.write(f"- Promedio por referencia: {self.session_stats['tiempo_total']/max(1,self.session_stats['referencias_procesadas']):.1f} segundos\n\n")
            
            f.write("CONFIGURACI√ìN UTILIZADA:\n")
            f.write(f"- NFE Steps: {self.nfe_steps}\n")
            f.write(f"- Sway Sampling: {self.sway_sampling_coef}\n")
            f.write(f"- CFG Strength: {self.cfg_strength}\n")
            f.write(f"- Speed: {self.speed}\n")
            f.write(f"- Fallback despu√©s de: {self.fallback_after_attempts} intentos\n\n")
            
            f.write(f"TEXTO PROCESADO ({len(self.frases)} frases):\n")
            for i, frase in enumerate(self.frases, 1):
                f.write(f"{i}. {frase}\n")
            f.write("\n")
            
            if self.session_stats['errores']:
                f.write("ERRORES ENCONTRADOS:\n")
                for i, error in enumerate(self.session_stats['errores'], 1):
                    f.write(f"{i}. {error}\n")
            else:
                f.write("‚úÖ No se encontraron errores durante la ejecuci√≥n.\n")
        
        print(f"üìã Resumen de sesi√≥n guardado: {summary_path.name}")

    def _merge_minimum_phrases(self, min_words: int = 4, max_merged_chars: int = 160):
        """Une frases con menos de min_words con la anterior si el resultado no supera max_merged_chars."""
        import re as _re_m
        if not self.frases:
            return
        merged = []
        for idx, frase in enumerate(self.frases):
            words = len(_re_m.findall(r'\b\w+\b', frase))
            if words < min_words and len(merged) > 0:
                prev = merged[-1]
                # Decidir separador adecuado
                sep = ', ' if not prev.endswith((',', ';', ':')) else ' '
                candidate = prev.rstrip().rstrip('.') + sep + frase.lstrip()
                if len(candidate) <= max_merged_chars:
                    merged[-1] = candidate
                    continue
            merged.append(frase)
        if len(merged) != len(self.frases):
            print(f"üîó Frases cortas fusionadas: {len(self.frases)} ‚Üí {len(merged)}")
        self.frases = merged

    def _clean_text_simple(self, text: str) -> str:
        """Limpieza m√≠nima de puntuaci√≥n conflictiva para el motor."""
        import re
        s = (text or '').strip()
        # Colapsar puntos/espacios duplicados
        s = re.sub(r'\s*\.\s*\.', '.', s)
        s = re.sub(r'\.\s+\.', '.', s)
        s = re.sub(r'\s{2,}', ' ', s)
        # Arreglar comillas y punto final duplicado
        s = re.sub(r'"\s*\.', '."', s)
        s = re.sub(r'\.(\s*\.)+$', '.', s)
        # Un √∫nico signo final
        s = re.sub(r'([.!?]){2,}$', r'\1', s)
        return s.strip()

    def _extend_text_for_engine(self, text: str) -> str:
        """Extiende ligeramente frases para dar tiempo al motor (solo para motor)."""
        s = (text or '').strip()
        if not s:
            return s
        if s.endswith('?'):
            return s + '...'
        if s.endswith('!'):
            return s + '...'
        if not s.endswith('.'):
            return s + '...'
        return s[:-1] + '...'

    def _split_text_for_engine_short(self, text: str) -> list:
        """Divide en 2 partes por coma/conector o por mitad de palabras."""
        import re
        s = (text or '').strip()
        commas = [m.start() for m in re.finditer(r',', s)]
        if commas:
            target = len(s) // 2
            split_pos = min(commas, key=lambda x: abs(x - target))
            left = s[:split_pos+1].strip()
            right = s[split_pos+1:].strip()
            if not left.endswith(('.', '!', '?')):
                left = left.rstrip(',') + '.'
            return [left, right]
        m = re.search(r'\s(y|pero|porque|aunque|entonces|as√≠ que|o)\s', s)
        if m:
            pos = m.start(0) + 1
            left = s[:pos].strip()
            right = s[pos:].strip()
            if not left.endswith(('.', '!', '?')):
                left += '.'
            return [left, right]
        words = s.split()
        if len(words) > 6:
            mid = len(words) // 2
            left = ' '.join(words[:mid]).strip()
            right = ' '.join(words[mid:]).strip()
            if not left.endswith(('.', '!', '?')):
                left += '.'
            return [left, right]
        return [s]


def listar_referencias_wav(refs_dir: Path):
    """Devuelve una lista de rutas a .wav en el directorio indicado (no recursivo)."""
    if not refs_dir.exists() or not refs_dir.is_dir():
        return []
    wavs = [p for p in sorted(refs_dir.iterdir()) if p.suffix.lower() == ".wav" and p.is_file()]
    return wavs


def main():
    # Directorio del script (contiene las referencias y el texto)
    script_dir = Path(__file__).parent.resolve()
    
    # Buscar archivo de texto en el directorio del script
    texto_usuario = None
    posibles_archivos_texto = [
        "texto.txt",
        "ejemplo_texto.txt", 
        "contenido.txt",
        "frases.txt"
    ]
    
    archivo_texto_encontrado = None
    for nombre_archivo in posibles_archivos_texto:
        archivo_path = script_dir / nombre_archivo
        if archivo_path.exists():
            archivo_texto_encontrado = archivo_path
            break
    
    if archivo_texto_encontrado:
        try:
            texto_usuario = archivo_texto_encontrado.read_text(encoding="utf-8")
            print(f"üìñ Texto cargado desde: {archivo_texto_encontrado.name}")
        except Exception as e:
            print(f"‚ùå Error leyendo {archivo_texto_encontrado.name}: {e}")
            print("üîÑ Usando texto por defecto...")
            texto_usuario = None
    else:
        print(f"üìù No se encontr√≥ archivo de texto en {script_dir}")
        print(f"   Archivos buscados: {', '.join(posibles_archivos_texto)}")
        print("üîÑ Usando texto por defecto...")

    # Buscar referencias .wav en el directorio del script
    referencias = listar_referencias_wav(script_dir)
    
    if len(referencias) == 0:
        print(f"‚ùå No se encontraron .wav de referencia en: {script_dir}")
        print("   Coloca los .wav de referencia en el mismo directorio del script")
        sys.exit(1)

    print(f"üîé Referencias encontradas ({len(referencias)}):")
    for r in referencias:
        print(f"   ‚Ä¢ {r.name}")

    # Crear generador con timestamp √∫nico para esta sesi√≥n
    generator = EstructuraComplejaMejorada(texto_usuario=texto_usuario)
    generator.session_stats['total_referencias'] = len(referencias)
    
    # Inicializar modelo una sola vez
    generator.initialize_model()

    print(f"\nüìÅ Sesi√≥n iniciada: {generator.session_dir.name}")
    print(f"üéØ Se generar√°n {len(referencias)} versiones completas")

    # Generar para cada referencia
    for ref_path in referencias:
        print("\n" + "#" * 80)
        print(f"‚ñ∂Ô∏è Generando versi√≥n completa usando referencia: {ref_path.name}")
        print("#" * 80)
        try:
            generator.generate_complete_speech_for_reference(ref_path)
        except KeyboardInterrupt:
            print("‚èπÔ∏è Proceso interrumpido por el usuario.")
            break
        except Exception as e:
            print(f"‚ùå Error generando con referencia {ref_path.name}: {e}")
            generator.session_stats['errores'].append(f"Error con {ref_path.name}: {e}")

    # Guardar resumen final de la sesi√≥n
    generator.save_session_summary()
    
    print(f"\nüèÅ Sesi√≥n completada: {generator.session_dir.name}")
    print(f"üìä Referencias procesadas: {generator.session_stats['referencias_procesadas']}/{generator.session_stats['total_referencias']}")
    if generator.session_stats['errores']:
        print(f"‚ö†Ô∏è Errores: {len(generator.session_stats['errores'])}")
    print(f"üìÇ Resultados en: {generator.session_dir}")


if __name__ == "__main__":
    import argparse
    parser = argparse.ArgumentParser()
    parser.add_argument('--resume', action='store_true', help='Reanuda desde el √∫ltimo estado guardado')
    args = parser.parse_args()

    if args.resume:
        # Modo reanudar (placeholder informativo)
        try:
            import json
            from pathlib import Path as _Path
            state = json.loads(_Path('resume_state.json').read_text(encoding='utf-8'))
            print(f"üîÑ Reanudar desde frase {state.get('phrase_idx','?')} con referencia {state.get('reference_file','?')}")
            # En una siguiente iteraci√≥n se puede saltar directamente a esa frase con l√≥gica adicional
        except Exception as e:
            print(f"‚ùå No se pudo reanudar: {e}")
        sys.exit(0)
    else:
        main()
